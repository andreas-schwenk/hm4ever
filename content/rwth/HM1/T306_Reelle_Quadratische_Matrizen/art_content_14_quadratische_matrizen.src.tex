%$Id:  $
\documentclass{mumie.article}
%$Id$
\begin{metainfo}
  \name{
    \lang{de}{Quadratische Matrizen}
    \lang{en}{Square matrices}
  }
  \begin{description} 
 This work is licensed under the Creative Commons License Attribution 4.0 International (CC-BY 4.0)   
 https://creativecommons.org/licenses/by/4.0/legalcode 

    \lang{de}{Beschreibung}
    \lang{en}{Description}
  \end{description}
  \begin{components}
\component{generic_image}{content/rwth/HM1/images/g_tkz_T403_Rotation.meta.xml}{T403_Drehung1}
\end{components}
  \begin{links}
  \link{generic_article}{content/rwth/HM1/T111neu_Matrizen/g_art_content_39_matrizen.meta.xml}{content_39_matrizen}
  \link{generic_article}{content/rwth/HM1/T111neu_Matrizen/g_art_content_43_matrizenmultiplikation.meta.xml}{content_43_matrizenmultiplikation}
  \link{generic_article}{content/rwth/HM1/T111neu_Matrizen/g_art_content_42_matrixaddition.meta.xml}{content_42_matrixaddition}
  \link{generic_article}{content/rwth/HM1/T401_Matrizenrechnung/g_art_content_02_matrizenmultiplikation.meta.xml}{matrix-mult}
    \link{generic_article}{content/rwth/HM1/T403_Quadratische_Matrizen,_Determinanten/g_art_content_08_inverse_matrix.meta.xml}{inverse-matrix}
    \link{generic_article}{content/rwth/HM1/T401_Matrizenrechnung/g_art_content_01_matrizen.meta.xml}{matrizen}
    \link{generic_article}{content/rwth/HM1/T402_Lineare_Gleichungssysteme/g_art_content_06_umformungen_rang.meta.xml}{umformungen}
    \link{generic_article}{content/rwth/HM1/T202_Reelle_Zahlen_axiomatisch/g_art_content_04_koerperaxiome.meta.xml}{koerperaxiome}
  \end{links}
%     \link{generic_article}{content/rwth/HM1/T112_Rechnen_mit_Matrizen/g_art_content_43_matrizenmultiplikation.meta.xml}{matrix-mult}
%     \link{generic_article}{content/rwth/HM1/T111_Matrizen,_lineare_Gleichungssysteme/g_art_content_39_matrizen.meta.xml}{matrizen}
%     \link{generic_article}{content/rwth/HM1/T112_Rechnen_mit_Matrizen/g_art_content_42_matrixaddition.meta.xml}{matrizen-add}
%     \link{generic_article}{content/rwth/HM1/T202_Reelle_Zahlen_axiomatisch/g_art_content_04_koerperaxiome.meta.xml}{koerperaxiome}
%     \link{generic_article}{content/rwth/HM1/T306_Reelle_Quadratische_Matrizen/g_art_content_15_inverse_matrix.meta.xml}{inverse-matrix}
%  \end{links}
  \creategeneric
\end{metainfo}
\begin{content}
\usepackage{mumie.ombplus}
\ombchapter{5}
\ombarticle{1}
\usepackage{mumie.genericvisualization}

\begin{visualizationwrapper}

\title{\lang{de}{Quadratische Matrizen}\lang{en}{Square matrices}}

\begin{block}[annotation]
 
  
\end{block}
\begin{block}[annotation]
  Im Ticket-System: \href{http://team.mumie.net/issues/11617}{Ticket 11617}\\
\end{block}

\begin{block}[info-box]
\tableofcontents
\end{block}


\lang{de}{
Wir haben bereits \link{content_39_matrizen}{Matrizen} und das Rechnen mit Matrizen kennengelernt. 
In diesem Abschnitt geht es speziell um quadratische Matrizen. Durch Matrizen beschreibt man eine 
sehr wichtige und sehr nützliche Klasse von Abbildungen zwischen mehrdimensionalen Räumen. 
Diese sogenannten linearen Abbildungen erhält man, indem man schlicht die Vektoren $x$ an 
$A\in M(m,n;\R)$ multipliziert: $x\mapsto A\cdot x$.
Quadratische $(n\times n)$-Matrizen beschreiben also lineare Selbstabbildungen des $\R^n$. Viele 
einfache geometrische Abbildungen lassen sich so darstellen.
}
\lang{en}{
We have already come across \link{content_39_matrizen}{matrices} and matrix calculations. 
In this section we focus on square matrices. We use these to describe a very important and useful 
class of maps between spaces with multiple dimensions. These so-called linear maps are given by 
multiplying each vector $x$ of a space by the matrix $A\in M(m,n;\R)$ that represents the map: 
$x\mapsto A\cdot x$. 
Square $(n\times n)$ matrices therefore can be used to describe maps of $\R^n$ onto itself. Many 
simple geometric maps can be described by matrices.
}
\begin{example}
\lang{de}{
Die Matrix 
$\left(\begin{smallmatrix}\cos(\alpha)&-\sin(\alpha)\\\sin(\alpha)&\cos(\alpha)\end{smallmatrix}\right)$ 
beschreibt eine Drehung im $\R^2$ um den Winkel $\alpha$ um den Nullpunkt gegen den Uhrzeigersinn,
}
\lang{en}{
The matrix 
$\left(\begin{smallmatrix}\cos(\alpha)&-\sin(\alpha)\\\sin(\alpha)&\cos(\alpha)\end{smallmatrix}\right)$ 
describes an anticlockwise rotation about the origin of $\R^2$ by the angle $\alpha$,
}
\begin{incremental}[\initialsteps{0}]
\step
\[ \begin{pmatrix}\cos(\alpha)&-\sin(\alpha)\\\sin(\alpha)&\cos(\alpha)\end{pmatrix}\cdot
\begin{pmatrix}x\\y\end{pmatrix}=
\begin{pmatrix}\cos(\alpha)\cdot x-\sin(\alpha)\cdot y\\\sin(\alpha)\cdot x+\cos(\alpha)\cdot y\end{pmatrix}.\]
\image{T403_Drehung1}
\end{incremental}
\end{example}
\lang{de}{
Auch wenn viele wichtige Abbildungen nicht derart beschrieben werden können, so reicht für 
praktische Zwecke oft ihre \glqq erste Näherung\grqq{}, also eine Approximation durch eine 
lineare Abbildung aus. Dafür studieren wir in diesem Kapitel grundlegende Eigenschaften 
quadratischer Matrizen.
}
\lang{en}{
Even though many important maps cannot be represented as a matrix, often a linear map can 
approximate it sufficiently for practical applications. Next we study some properties of 
square matrices.
}




\section{\lang{de}{Quadratische Matrizen}\lang{en}{Square matrices}}


\begin{definition}\label{def:quadr-mat}
\lang{de}{Eine \notion{quadratische Matrix} ist eine Matrix mit genauso vielen Zeilen wie Spalten.}
\lang{en}{A \notion{square matrix} is a matrix with the same amount of rows and columns.}
\end{definition}

\lang{de}{
Im Folgenden ist stets $n$ eine natürliche Zahl. Wir betrachten die Menge
$M(n,n;\R)$ der (quadratischen) $(n\times n)$-Matrizen. Statt $M(n,n;\R)$
schreiben wir auch kürzer $M({n};\R)$. Eine weitere gebräuchliche Bezeichnung dafür ist $M_n(\R)$.
}
\lang{en}{
In the following, $n$ is always taken to be a natural number. We consider the set $M(n,n;\R)$ of 
(square) $(n\times n)$- matrices. We shorten $M(n,n;\R)$ to $M({n};\R)$. In other literature, the 
notation $M_n(\R)$ is also used.
}

\begin{definition}\label{def:wichtige-quadr-mat}
\lang{de}{
Für wichtige quadratische Matrizen und Arten von Matrizen gibt es noch besondere Bezeichnungen:
}
\lang{en}{
There are certain important square matrices which have special notation:
}
\begin{tabs*}[\initialtab{0}]
\tab{\lang{de}{Nullmatrix $0_n$}\lang{en}{Zero matrix $0_n$}}
       \lang{de}{
       Die $(n \times n)$-Nullmatrix ist die Matrix, deren Eintr\"age alle gleich $0$ sind, also 
       }
       \lang{en}{
       The $(n \times n)$-zero matrix is the matrix whose entries are all $0$,
       }
       \begin{equation*}
       0_{n} := \begin{pmatrix}
            0 & 0 & \cdots & 0 \\
            0 & 0 & \cdots & 0 \\
            \vdots & \vdots & \ddots & \vdots \\
            0 & 0 & \cdots & 0 
           \end{pmatrix} \in M(n;\R
          ).
       \end{equation*}
\tab{\lang{de}{Einheitsmatrix $E_n$}\lang{en}{Identity matrix $E_n$}}
       \lang{de}{
       Bei der $ (n \times n)$-Einheitsmatrix sind alle Eintr\"age auf der Hauptdiagonalen gleich 
       $1$ und alle anderen gleich $0$, also 
       }
       \lang{en}{
       The $ (n \times n)$-identity matrix is the matrix whose leading diagonal entries are all 
       $1$, and whose other entries are all $0$,
       }
       \begin{equation*}
       E_{n} := \begin{pmatrix}
                1 & 0 & \cdots & 0 & 0 \\
                0 & 1 & \cdots & 0 & 0 \\
                \vdots & \vdots & \ddots & \vdots & \vdots \\
                0 & 0 & \cdots & 1 & 0 \\
                0 & 0 & \cdots & 0 & 1 
                \end{pmatrix} \in M(n;\R).
  \end{equation*}
\tab{\lang{de}{Diagonalmatrizen}\lang{en}{Diagonal matrices}}
\lang{de}{Eine Matrix der Form}
\lang{en}{A matrix of the form}
       \begin{equation*}
       \begin{pmatrix}
       a_{11} & 0 & \cdots & 0 & 0 \\
       0 & a_{22} & \cdots & 0 & 0 \\
       \vdots & \vdots & \ddots & \vdots & \vdots \\
       0 & 0 & \cdots & a_{n-1,n-1} & 0 \\
       0 & 0 & \cdots & 0 & a_{nn} 
       \end{pmatrix} \in M(n;\R)
       \end{equation*}
       \lang{de}{
       mit $a_{ii}\in \R$ nennt man \notion{Diagonalmatrix}.
       Hier stehen \emph{h\"ochstens} auf der Diagonalen von $0$ verschiedene Eintr\"age. 
       Man schreibt auch kurz $\text{diag}(a_{11},a_{22},\ldots,a_{nn})$.
       }
       \lang{en}{
       where $a_{ii}\in \R$ is called a \notion{diagonal matrix}. 
       In a diagonal matrix, only the entries on the leading diagonal may be non-zero. 
       We use the notation $\text{diag}(a_{11},a_{22},\ldots,a_{nn})$.
       }
  
\tab{\lang{de}{Obere Dreiecksmatrizen}\lang{en}{Upper triangular matrices}}
      \lang{de}{Eine Matrix der Form}
      \lang{en}{A matrix of the form}
      \begin{equation*}
       \begin{pmatrix}
       a_{11} & a_{12} & \cdots & a_{1,n-1} & a_{1n} \\
       0 & a_{22} & \cdots & a_{2,n-1} & a_{2n} \\
       \vdots & \vdots & \ddots & \vdots & \vdots \\
       0 & 0 & \cdots & a_{n-1,n-1} & a_{n-1,n} \\
       0 & 0 & \cdots & 0 & a_{nn} 
       \end{pmatrix} \in M(n;\R)
       \end{equation*}
       \lang{de}{
       mit $a_{ij}\in \R$ nennt man \notion{obere Dreiecksmatrix} (nur oberhalb oder auf der 
       Diagonalen dürfen die Eintr\"age ungleich $0$ sein).
       }
       \lang{en}{
       where $a_{ij}\in \R$ is called an \notion{upper triangular matrix}. 
       In an upper triangular matrix, only the entries on and above the leading diagonal may be 
       non-zero.
       }
\tab{\lang{de}{Untere Dreiecksmatrizen}\lang{en}{Lower triangular matrices}}
       \lang{de}{Analog zur oberen Dreiecksmatrix nennt man eine Matrix der Form}
       \lang{en}{Analagously to the upper triangular matrix, a matrix of the form}
       \begin{equation*}
       \begin{pmatrix}
       a_{11} & 0 & \cdots & 0 & 0 \\
       a_{21} & a_{22} & \cdots & 0 & 0 \\
       \vdots & \vdots & \ddots & \vdots & \vdots \\
       a_{n-1,1} & a_{n-1,2} & \cdots & a_{n-1,n-1} & 0 \\
       a_{n1} & a_{n2} & \cdots & a_{n,n-1} & a_{nn} 
       \end{pmatrix} \in M(n;\R)
       \end{equation*}
       \lang{de}{
       mit $a_{ij}\in \R$ eine \notion{untere Dreiecksmatrix} (nur unterhalb oder auf der 
       Diagonalen dürfen die Eintr\"age ungleich $0$ sein).
       }
       \lang{en}{
       where $a_{ij}\in \R$ is called a \notion{lower triangular matrix}. 
       In a lower triangular matrix, only the entries on and below the leading diagonal may be 
       non-zero.
       }
\end{tabs*}
\end{definition}

\begin{example}\label{ex:einfache_bsp_quad_matrizen}
\begin{enumerate}
\item \lang{de}{
      Die Nullmatrix $0_n$ und die Einheitsmatrix $E_n$ sind spezielle Diagonalmatrizen. Sie 
      sind auch untere und obere Dreiecksmatrizen.
      }
      \lang{en}{
      The zero matrix and the identity matrix $E_n$ are special cases of diagonal matrices, 
      which themselves are special cases of both upper and lower triangular matrices.
      }
\item \lang{de}{Jede Diagonalmatrix ist sowohl eine untere als auch eine obere Dreiecksmatrix.}
      \lang{en}{Every diagonal matrix is both an upper and a lower triangular matrix.}
\item \lang{de}{
      Elementarmatrizen: Die folgenden, sogenannten Elementarmatrizen können dazu benutzt werden,
      \link{umformungen}{elementare Zeilenumformungen durch Matrizenmultiplikation} zu beschreiben. 
      Die Matrizen
      }
      \lang{en}{
      Elementary matrices: The following so-called elementary matrices can be used to describe 
      \link{umformungen}{elementary row operations using matrix multiplication}. 
      The matrices
      }
\[
\begin{mtable}[\cellaligns{cc}]
 { \text{\lang{de}{i-te Spalte }\lang{en}{i-th column}}} &\\
  \downarrow        &
\end{mtable}
\] \[
M_{i}(r) \ = 
\left(
\begin{matrix}
1       &        &        &        &        &            &        &   &            \\
        & \:\ddots &        &        &        &            &        &   &            \\ 
        &        &        & 1      &        &            &        &   &  \\
        &        &        &        & r      &            &        &   &  \\
        &        &        &        &        & 1          &        &   &  \\
        &        &        &        &        &            & \:\ddots &   &  \\
        &        &        &        &        &            &        & 1 & 
\end{matrix}
\right)
\begin{mtable}[\cellaligns{c}]
\\
\\
\\
\leftarrow {\text{\lang{de}{i-te Zeile}\lang{en}{i-th row}}} \\
\\
\\
\\
\end{mtable}
 \]
 \lang{de}{
 für $r\in \R, r\neq 0$ und $i\in \{1,\ldots, n\}$ sind Diagonalmatrizen (und obere und untere 
 Dreiecksmatrizen).
 \\\\
 Die Matrizen
 }
 \lang{en}{
 where $r\in \R, r\neq 0$ and $i\in \{1,\ldots, n\}$ are diagonal matrices (and so upper and 
 lower triangular matrices).
 \\\\
 The matrices
 }
  \[
\begin{mtable}[\cellaligns{cc}]
     &   & { \text{\lang{de}{j-te Spalte }\lang{en}{j-th column }}}& \\
     &   & \downarrow        &
\end{mtable}
\]
\[
A_{ij}(r)=
\left(
\begin{matrix}
1       &                &        &        &            &        &   &            \\
        & \ddots         &        &        &            &        &   &            \\ 
        &                & 1      &        & r          &        &   &  \\
        &                &        & \ddots &            &        &   &  \\
        &                &        &        & 1          &        &   &  \\
        &                &        &        &            & \ddots &   &  \\
        &                &        &        &            &        & 1 & 
\end{matrix}
\right)
\begin{mtable}[\cellaligns{c}]
\\
\leftarrow {\text{\lang{de}{i-te Zeile}\lang{en}{i-th row}}} \\
\\
\\
\\
\end{mtable}
\]
 \lang{de}{
 für $r\in \R$, $r\neq 0$ und $i,j\in \{1,\ldots, n\}, i\neq j$  sind untere Dreiecksmatrizen, wenn 
 $i>j$, und obere Dreiecksmatrizen, wenn $i<j$. Es sind aber keine Diagonalmatrizen, da stets ein 
 Eintrag außerhalb der Diagonalen (nämlich der an der Stelle $(i,j)$) ungleich $0$ ist.
 \\\\
 Die Matrizen
 }
 \lang{en}{
 where $r\in \R$, $r\neq 0$ and $i,j\in \{1,\ldots, n\}, i\neq j$ are lower triangular matrices if 
 $i>j$, and upper triangular matrices if $i<j$. These are not diagonal matrices, as they have a 
 non-zero entry outside the leading diagonal (at $(i,j)$).
 \\\\
 The matrices
 }
 \[
\begin{mtable}[\cellaligns{cccc}]
 { \text{\lang{de}{i-te Spalte}\lang{en}{i-th column}}} &  &   {\text{\lang{de}{j-te Spalte }\lang{en}{j-th column}}} &   \\
  \downarrow           &  & \downarrow &
\end{mtable}
\]
\[ V_{ij} \ \ \ \ = \ \ \ \ 
\left(
\begin{matrix}
1       &        &        &        &        &            &        &   &   &        &   &  \\
        & \ddots &        &        &        &            &        &   &   &        &   &  \\ 
        &        &  1     &        &        &            &        &   &   &        &   &  \\
        &        &        & 0      &        &            &        & 1 &   &        &   &  \\
        &        &        &        & 1      &            &        &   &   &        &   &  \\
        &        &        &        &        & \ddots     &        &   &   &        &   &  \\
        &        &        &        &        &            & 1      &   &   &        &   &  \\
        &        &        & 1      &        &            &        & 0 &   &        &   &  \\
        &        &        &        &        &            &        &   & 1 &        &   &  \\
        &        &        &        &        &            &        &   &   & \ddots &   &  \\
        &        &        &        &        &            &        &   &   &        & 1 & 
\end{matrix}
\right)
\begin{mtable}[\cellaligns{c}]
\\
\\
\leftarrow {\text{\lang{de}{i-te Zeile}\lang{en}{i-th row}}} \\
\\
\\
\\
\leftarrow {\text{\lang{de}{j-te Zeile}\lang{en}{j-th row}}} \\
\\
\\
\end{mtable}
 \]
 \lang{de}{
 für $i,j\in \{1,\ldots, n\}$, $i\neq j$ sind weder untere noch obere Dreiecksmatrizen (und erst 
 recht keine Diagonalmatrizen), da sowohl oberhalb der Diagonalen, als auch unterhalb der 
 Diagonalen Einträge ungleich $0$ vorhanden sind.
 }
 \lang{en}{
 where $i,j\in \{1,\ldots, n\}$, $i\neq j$ are neither lower nor upper triangular matrices (and 
 certainly not diagonal matrices), as they have there are non-zero entries both above and below the 
 diagonals.
 }
\end{enumerate}
\end{example}

\section{\lang{de}{Rechnen mit quadratischen Matrizen}
         \lang{en}{Square matrix calculations}}\label{sec:rechnen-quadr-mat}

\lang{de}{
In den Abschnitten \link{content_42_matrixaddition}{Matrixaddition} und 
\link{content_43_matrizenmultiplikation}{Matrizenmultiplikation}
%\link{matrizen}{Matrizen} und \link{matrix-mult}{Matrizenmultiplikation}
wurden schon Matrizen addiert und multipliziert. Während bei der Addition die Abmessungen
der Matrizen gleich sein müssen, muss bei der Multiplikation die Zeilenzahl der zweiten Matrix 
gleich der Spaltenzahl der ersten Matrix sein. Sind $A$ und $B$ also quadratische $(n\times n)$-Matrizen mit 
Einträgen in $\R$, so sind beide Bedingungen erfüllt, und daher ist sowohl die Summe
}
\lang{en}{
In the sections on \link{content_42_matrixaddition}{matrix addition} and 
\link{content_43_matrizenmultiplikation}{matrix multiplication} 
we explained how to add and multiply matrices. Although both dimensions of two matrices must be the 
same in order to add them, multiplication of two matrices only requires the number of columns of the first 
matrix to be equal to the number of rows of the second matrix. If $A$ and $B$ are square 
$(n\times n)$-matrices with entries in $\R$, then they have the same dimensions, so both the sum
}
\[ A+B \]
\lang{de}{als auch das Produkt}
\lang{en}{and the product}
\[ A\cdot B\]
\lang{de}{
definiert. In beiden Fällen ist das Ergebnis wieder eine $(n\times n)$-Matrix.
\\\\
Natürlich gelten auch die allgemeinen 
\ref[content_42_matrixaddition][Rechenregeln für die Addition]{rule:rechenregeln} und 
für die \ref[content_43_matrizenmultiplikation][Matrizenmultiplikation]{rule:rechenregeln}
in diesem speziellen Fall:
}
\lang{en}{
of the two matrices are defined. In both cases, the result of the operation is another $(n\times n)$-matrix.
\\\\
Of course, the general \ref[content_42_matrixaddition][rules for matrix addition]{rule:rechenregeln} and 
those for \ref[content_43_matrizenmultiplikation][matrix multiplication]{rule:rechenregeln} in the special 
case of square matrices:
}



\begin{rule}
\lang{de}{
Auf der Menge $M(n;\R)$ der $(n\times n)$-Matrizen mit Einträgen in $\R$ sind die Addition $+$ und die 
Multiplikation $\cdot$ definiert, die zwei Matrizen $A$ und $B$ wieder eine $(n\times n)$-Matrix, nämlich
deren Summe $A+B$ bzw. deren Produkt $A\cdot B$ zuordnen. 
Es gelten für alle $A,B,C\in M(n;\R)$:
}
\lang{en}{
Addition $+$ and multiplication $\cdot$ are defined on the set $M(n;\R)$ of $(n\times n)$-matrices with 
entries in $\R$, and they yield another $(n\times n)$-matrix. For all $A,B,C\in M(n;\R)$ we have:
}

   \emph{\lang{de}{Rechenregeln der Addition:}\lang{en}{Rules for addition:}} 
    \begin{itemize}
        \item $A+B=B+A$ $\quad$ \lang{de}{(Kommutativgesetz)}\lang{en}{(Commutativity law)}
        \item $\left(A+B\right)+C=A+\left(B+C\right)$ $\quad$
            \lang{de}{(Assoziativgesetz)}\lang{en}{(Associativity law)}
        \item \lang{de}{
              Die Nullmatrix $0_n\in M(n;\R)$ erfüllt $\nowrap{A+0_n=A}$ für alle $A\in M(n;\R)$ 
              (neutrales Element der Addition).
              }
              \lang{en}{
              The zero matrix $0_n\in M(n;\R)$ satisfies $\nowrap{A+0_n=A}$ for all $A\in M(n;\R)$ 
              (additive identity).
              }
        \item \lang{de}{Für jede Matrix $A\in M(n;\R)$ ist $A+(-A)=0_n$.}
              \lang{en}{For every matrix $A\in M(n;\R)$ we have $A+(-A)=0_n$.}
    \end{itemize}
    
    \\    
    \emph{\lang{de}{Rechenregeln der Multiplikation:}\lang{en}{Rules for multiplication:}} 
    \begin{itemize}
%        \item[(M1)] $a\cdot b=b\cdot a$ $\quad$ (Kommutativgesetz)
        \item $A\cdot \left(B\cdot C\right) = \left(A\cdot B\right)\cdot 
            C$ $\quad$ \lang{de}{(Assoziativgesetz)}\lang{en}{(Associativity law)}
        \item \lang{de}{
              Die Einheitsmatrix $E_n\in  M(n;\R)$ erfüllt $A\cdot E_n=E_n\cdot A=A$ 
              (neutrales Element der Multiplikation).
              }
              \lang{en}{
              The identity matrix $E_n\in  M(n;\R)$ satisfies $A\cdot E_n=E_n\cdot A=A$ 
              (multiplicative identity).
              }
    \end{itemize}
    
    \\
    \emph{\lang{de}{Vertr\"aglichkeit von Addition und Multiplikation:}
          \lang{en}{Compatibility of addition and multiplication:}} \\
    \begin{itemize}
        \item $\left(A+B\right)\cdot C=A\cdot C+B\cdot C$ $\quad$ \lang{de}{und}\lang{en}{and}\\
        $A\cdot \left(B+C\right)=A\cdot B+A\cdot C$ $\quad$
            \lang{de}{(Distributivgesetze)}\lang{en}{(Distributivity law)}
    \end{itemize}
\end{rule}


\begin{remark}
\lang{de}{
Vergleicht man die Rechenregeln mit den \ref[koerperaxiome][Körperaxiomen]{sec:axiome}, so stellt man 
fest, dass lediglich die Kommutativität der Multiplikation und die Existenz inverser Elemente bzgl. der 
Multiplikation nicht aufgeführt sind. Diese gelten für Matrizen mit $n\geq 2$ im Allgemeinen nicht.
}
\lang{en}{
Comparing the above rules to the \ref[koerperaxiome][field axioms]{sec:axiome}, we immediately see that 
only commutativity of multiplication and the existence of multiplicative inverses are missing. In 
general, these do not hold for square matrices with $n\geq 2$.
}

\emph{\lang{de}{Gegenbeispiel zur Kommutativität:}\lang{en}{Counterexample to commutativity:}}
\\
\lang{de}{Für}
\lang{en}{For}
$A = \begin{pmatrix}
1 & 2 \\ 0& 1
\end{pmatrix}$ \lang{de}{und}\lang{en}{and}  $B = \begin{pmatrix}
2 & 0\\ 1&1 \end{pmatrix} \in M(2;\R) 
$ \lang{de}{gilt}\lang{en}{we have}
\[ A\cdot B=\begin{pmatrix}
1 & 2 \\ 0& 1
\end{pmatrix}\cdot \begin{pmatrix}
2 & 0\\ 1&1 \end{pmatrix}=\begin{pmatrix} 4&2\\ 1&1\end{pmatrix}, \]
\lang{de}{aber}\lang{en}{but} 
\[ B\cdot A=\begin{pmatrix}
2 & 0\\ 1&1 \end{pmatrix}\cdot\begin{pmatrix}
1 & 2 \\ 0& 1
\end{pmatrix}=\begin{pmatrix} 2&4\\ 1&3\end{pmatrix}. \]
\lang{de}{Es gilt also $A\cdot B\neq  B\cdot A$.}
\lang{en}{We thus have $A\cdot B\neq  B\cdot A$.}

\emph{\lang{de}{Beispiel für eine Matrix, die kein multiplikatives Inverses besitzt:}
      \lang{en}{Example of a matrix that does not have a multiplicative inverse:}}
\\
\lang{de}{Zur Matrix}\lang{en}{Given the matrix} 
$C=\begin{pmatrix}
1 & 0 \\ 0& 0
\end{pmatrix}$ 
\lang{de}{gibt es keine Matrix $D$ mit $C\cdot D=E_2$, denn in jedem Produkt} 
\lang{en}{there does not exist a matrix $D$ with $C\cdot D=E_2$, as for the product}
\[ \begin{pmatrix}
1 & 0 \\ 0& 0
\end{pmatrix}\cdot \begin{pmatrix} d_{11}&d_{12}\\d_{21}&d_{22}\end{pmatrix}=\begin{pmatrix}d_{11}&d_{12}\\0&0\end{pmatrix} \]
\lang{de}{
ist stets die zweite Zeile gleich $(0 \ 0)$ unabhängig davon, welche Einträge $d_{ij}$ wir in $D$ 
wählen. Ebenso gibt es keine Matrix $D$ mit $D\cdot C=E_2$, denn im Produkt
}
\lang{en}{
the second row is always equal to $(0 \ 0)$, independently of which entries $d_{ij}$ we choose in 
$D$. Similarly there exists no matrix $D$ with $D\cdot C=E_2$, as for the product 
}
\[D\cdot \begin{pmatrix}
1 & 0 \\ 0& 0
\end{pmatrix} \]
\lang{de}{
ist stets die zweite Spalte gleich $\left(\begin{smallmatrix} 0\\ 0 \end{smallmatrix}\right)$.
\\\\
Solche Beispiele findet man ebenso einfach für beliebiges $n\geq 2$.
}
\lang{en}{
the second row is always equal to $\left(\begin{smallmatrix} 0\\ 0 \end{smallmatrix}\right)$.
\\\\
Such a counterexample can be easily found for any $n\geq 2$.
}
\end{remark}



\section{\lang{de}{Invertierbare Matrizen}
         \lang{en}{Invertible matrices}}\label{sec:invertierbare-matrizen}

\lang{de}{
Da es nicht für jede Matrix $A\in M(n;\R)$ eine Matrix $B\in M(n;\R)$ mit $A\cdot B=E_n$ gibt,
erhalten solche Matrizen, für die es so ein $B$ gibt, einen besonderen Namen.
}
\lang{en}{
As not every matrix $A\in M(n;\R)$ has a corresponding matrix $B\in M(n;\R)$ such that 
$A\cdot B=E_n$, the matrices for which such a $B$ exists are given a special name.
}

\begin{definition}\label{def:invertierbar}
\lang{de}{
Eine Matrix $A\in M(n;\R)$ heißt \notion{invertierbar}, wenn es eine Matrix $B\in M(n;\R)$ mit 
$A\cdot B=E_n$ gibt.
\\\\
In diesem Fall wird die Matrix $B$ \notion{inverse Matrix} zu $A$ genannt und mit $A^{-1}$ 
bezeichnet.
}
\lang{en}{
A matrix $A\in M(n;\R)$ is called \notion{invertible} if there exists a matrix $B\in M(n;\R)$ 
such that $A\cdot B=E_n$.
\\\\
In this case we call $B$ the \notion{inverse matrix} of $A$ and denote it $A^{-1}$.
}
\end{definition}
\begin{example}
\lang{de}{
Die Einheitsmatrix $E_n$ ist invertierbar mit inverser Matrix $E_n$, denn $E_n\cdot E_n=E_n$.
}
\lang{en}{
The identity matrix $E_n$ is invertible with inverse matrix $E_n$, as $E_n\cdot E_n=E_n$.
}
\end{example}

\begin{remark}\label{rem:links-invers}
\begin{enumerate}
\item \lang{de}{
      Wenn $A$ invertierbar ist, dann gibt es auch nur genau eine Matrix $B$ mit $A\cdot B=E_n$, 
      weshalb es gerechtfertigt ist, von \textbf{der} inversen Matrix $A^{-1}$ von $A$ zu sprechen.\\
      }
      \lang{en}{
      If $A$ is invertible, then there exists precisely one matrix $B$ such that $A\cdot B=E_n$. This 
      uniqueness lets us speak of \textbf{the} inverse matrix $A^{-1}$ of $A$.\\
      }
\item \lang{de}{
      Gibt es andererseits zu $A\in M(n;\R)$ eine Matrix $B\in M(n;\R)$ mit $B\cdot A=E_n$, so 
      gilt auch $A\cdot B=E_n$. Man hätte also alternativ definieren können, dass $A$ invertierbar ist, 
      wenn es eine Matrix $B\in M(n;\R)$ mit $B\cdot A=E_n$ gibt.
      }
      \lang{en}{
      Given $A\in M(n;\R)$, if there exists a matrix $B\in M(n;\R)$ such that $B\cdot A=E_n$, we also 
      have $A\cdot B=E_n$. We could thus also have defined $A$ to be invertible if there exists a 
      matrix $B\in M(n;\R)$ such that $B\cdot A=E_n$.
      }
\item \lang{de}{
      Die inverse Matrix $A^{-1}$ erfüllt also nicht nur $A\cdot A^{-1}=E_n$, sondern auch
      }
      \lang{en}{
      The inverse matrix $A^{-1}$ not only satisfies $A\cdot A^{-1}=E_n$, but also
      }
      \[ A^{-1}\cdot A=E_n. \]
\end{enumerate}
\lang{de}{
Die Begründungen für diese Tatsachen werden im \link{inverse-matrix}{nächsten Abschnitt} gegeben, wo wir 
erklären, wie man die inverse Matrix berechnen kann.
}
\lang{en}{
The reasoning behind these facts is given in the \link{inverse-matrix}{next section}, in which we learn 
to compute inverse matrices.
}
\end{remark}
\begin{block}[warning]
\lang{de}{
Da die Matrizenmultiplikation nicht kommutativ ist, sollte die für Zahlen übliche Bruchschreibweise 
$\frac{a}{b}$ für $ab^{-1}$ bei Matrizen nicht verwendet werden. Die für Brüche von Zahlen geltenden 
Rechenregeln
}
\lang{en}{
As matrix multiplication is not commutative, the usual notation $\frac{a}{b}$ for $ab^{-1}$ should not 
be used. The rules
}
\[ \frac{a}{b}\cdot \frac{c}{d}=\frac{ac}{bd}\quad \text{\lang{de}{und}\lang{en}{and}} \quad \frac{a}{b}+\frac{c}{d}=\frac{ad+bc}{bd}\]
\lang{de}{wären nämlich für Matrizen falsch!}
\lang{en}{work for real numbers, but not for matrices!}
\end{block}

\begin{example}\label{ex:erste-bsp_inverse_matrix}
\begin{tabs*}
\tab{\lang{de}{Beispiel 1}\lang{en}{Example 1}} 
\lang{de}{Die Matrix}
\lang{en}{The matrix} 
$A = \begin{pmatrix}
1 & 2 \\ 0& 1
\end{pmatrix} \in M(2;\R) $ 
\lang{de}{ist invertierbar.}
\lang{en}{is invertible.}
\begin{incremental}[\initialsteps{0}]
\step
\lang{de}{Ihre inverse Matrix ist}
\lang{en}{It has inverse matrix}
$ A^{-1}=\begin{pmatrix}
1 & -2 \\ 0& 1
\end{pmatrix}$,
\step
\lang{de}{denn}
\lang{en}{as}
\[  A\cdot A^{-1}= \begin{pmatrix}
1 & 2 \\ 0& 1
\end{pmatrix} \cdot \begin{pmatrix}
1 & -2 \\ 0& 1
\end{pmatrix} = \begin{pmatrix}
1\cdot 1+2\cdot 0 & 1\cdot (-2)+2\cdot 1 \\ 0\cdot 1+1\cdot 0 & 0\cdot (-2)+1\cdot 1
\end{pmatrix}= \begin{pmatrix}
1 & 0 \\ 0& 1
\end{pmatrix}. \]
\end{incremental}
\tab{\lang{de}{Beispiel 2}\lang{en}{Example 2}}
\lang{de}{Die Matrix}
\lang{en}{The matrix} 
$B = \begin{pmatrix}
3 & 2 \\ -1& 1
\end{pmatrix} \in M(2;\R) $ 
\lang{de}{ist invertierbar.}
\lang{en}{is invertible.}
\begin{incremental}[\initialsteps{0}]
\step
\lang{de}{Ihre inverse Matrix ist}
\lang{en}{It has inverse matrix}
$B^{-1}=\begin{pmatrix}
1/5 & -2/5 \\ 1/5& 3/5
\end{pmatrix}, $
\step
\lang{de}{denn}
\lang{en}{as}
\[  B\cdot B^{-1}= \begin{pmatrix}
3 & 2 \\ -1& 1
\end{pmatrix} \cdot \begin{pmatrix}
1/5 & -2/5 \\ 1/5& 3/5
\end{pmatrix} = \begin{pmatrix}
3/5+2/5 & -6/5+6/5 \\ -1/5+1/5 & 2/5+3/5
\end{pmatrix}= \begin{pmatrix}
1 & 0 \\ 0& 1
\end{pmatrix}. \]
\lang{de}{Man sieht hier auch direkt}
\lang{en}{We also see that}
\[ B^{-1}\cdot B=\begin{pmatrix}
1/5 & -2/5 \\ 1/5& 3/5
\end{pmatrix} \cdot \begin{pmatrix}
3 & 2 \\ -1& 1
\end{pmatrix} = \begin{pmatrix}
3/5+2/5 & 2/5-2/5 \\ 3/5-3/5 & 2/5+3/5
\end{pmatrix}= \begin{pmatrix}
1 & 0 \\ 0& 1
\end{pmatrix}. \]
\end{incremental}
\tab{\lang{de}{Diagonalmatrizen}\lang{en}{Diagonal matrices}}
\lang{de}{
Eine Diagonalmatrix $D=\text{diag}(d_1,d_2,\ldots,d_n)\in M(n;\R)$ ist invertierbar, wenn alle 
$d_j\neq 0$, $j=1,\ldots,n$.
}
\lang{en}{
A diagonal matrix $D=\text{diag}(d_1,d_2,\ldots,d_n)\in M(n;\R)$ is invertible if 
$d_j\neq 0$, $j=1,\ldots,n$.
}
\begin{incremental}[\initialsteps{0}]
\step
\lang{de}{Die inverse Matrix ist dann}
\lang{en}{The inverse matrix is then}
$D^{-1}=\text{diag}(d_1^{-1},d_2^{-1},\ldots, d_n^{-1})$, 
\step
\lang{de}{denn}
\lang{en}{as}
\[\text{diag}(d_1,d_2,\ldots,d_n)\cdot\text{diag}(d_1^{-1},d_2^{-1},\ldots, d_n^{-1})=\text{diag}(d_1d_1^{-1},d_2d_2^{-1},\ldots, d_n d_n^{-1})=\text{diag}(1,1,\ldots,1)=E_n.\]
\end{incremental}
\end{tabs*}
\end{example}

%\begin{quickcheckcontainer}
\begin{quickcheck}
  \type{input.function}
  \field{rational}
  \displayprecision{3}
  
 
  \begin{variables}
   \drawFromSet{d1}{2,3,4,5,6,7,8,9}
   \drawFromSet{d4}{2,3,4,5,6,7,8,9}
   \function[calculate]{a1}{1/d1}
   \function[calculate]{a2}{0}
   \function[calculate]{a3}{0}
   \function[calculate]{a4}{1/d4}
   \function[calculate]{b1}{-i}
   \function[calculate]{b4}{i}
   \function[calculate]{b2}{0}
   
 \end{variables}
 
  \text{\lang{de}{Bestimmen Sie die inverse Matrix}
    \lang{en}{Determine the inverse matrix} 
    $B=\begin{pmatrix}b_{11}&b_{12}\\b_{21}&b_{22}\end{pmatrix}$ 
    \lang{de}{von}
    \lang{en}{of} 
    $A=\begin{pmatrix}\var{d1}&0\\0&\var{d4}\end{pmatrix}\in M(2;\R)$.
    \\\\
    \lang{de}{Antwort:}
    \lang{en}{Solution:} 
    $b_{11}=$\ansref, $b_{12}=$\ansref, $b_{21}=$\ansref, $b_{22}=$\ansref.
    }
  
 
  \begin{answer}
    \solution{a1}
  \end{answer}
   \begin{answer}
    \solution{a2}
   \end{answer}
   \begin{answer}
    \solution{a3} 
  \end{answer}
  \begin{answer}
    \solution{a4}
   \end{answer}
\end{quickcheck}
%\end{quickcheckcontainer}

\lang{de}{Auch alle Elementarmatrizen sind invertierbar:}
\lang{en}{Every elementary matrix is invertible:}

\begin{example}
\lang{de}{
Die Elementarmatrizen $M_i(r)$, $A_{ij}(r)$ und $V_{ij}$ mit $r\in \R$, $r\neq 0$, 
$i,j\in \{1,\ldots, n\}$, $i\neq j$, sind alle invertierbar mit Inversen $M_i(\frac{1}{r})$, 
$A_{ij}(-r)$ bzw. $V_{ij}$, denn
}
\lang{en}{
The elementary matrices $M_i(r)$, $A_{ij}(r)$ and $V_{ij}$ with $r\in \R$, $r\neq 0$, 
$i,j\in \{1,\ldots, n\}$, $i\neq j$, are all invertible with inverses $M_i(\frac{1}{r})$, 
$A_{ij}(-r)$ and $V_{ij}$ respectively, as
}
\begin{eqnarray*}
 M_i(r) \cdot M_i(\frac{1}{r}) &=& M_i(1)=E_n, \\
A_{ij}(r) \cdot A_{ij}(-r) &=& A_{ij}(r-r)= E_n, \\
V_{ij}\cdot V_{ij}&=& E_n.
\end{eqnarray*} 
\end{example}







% Wir hatten im Abschnitt \link{matrizen}{Matrizen} schon Matrizen kennengelernt und auch schon das Rechnen mit 
% Matrizen.
% In diesem Abschnitt soll es speziell um quadratische Matrizen gehen.

% \section{Quadratische Matrizen}


% \begin{definition}
% Eine \notion{quadratische Matrix} ist eine Matrix mit gleich vielen Zeilen wie Spalten.
% \end{definition}

% Im Folgenden ist stets $n$ eine natürliche Zahl, $\R$ der Körper der reellen Zahlen, und wir betrachten die Menge
% $M(n,n;\R)$ der (quadratischen) $(n\times n)$-Matrizen mit reellen Einträgen. Statt $M(n,n;\R)$
% schreiben wir auch kürzer $M({n};\R)$.

% \begin{definition}
% Für wichtige quadratische Matrizen und Arten von Matrizen gibt es noch besondere Bezeichnungen:
% \begin{tabs*}[\initialtab{0}]
% \tab{Nullmatrix $0_n$}
% Die $(n \times n)$-Nullmatrix ist eine Matrix, deren Eintr\"age alle gleich $0$ sind, also 
%        \begin{equation*}
%        0_{n} := \begin{pmatrix}
%             0 & 0 & \cdots & 0 \\
%             0 & 0 & \cdots & 0 \\
%             \vdots & \vdots & \ddots & \vdots \\
%             0 & 0 & \cdots & 0 
%            \end{pmatrix} \in M(n;\R).
%        \end{equation*}
% \tab{Einheitsmatrix $E_n$}
%  Bei der $ (n \times n)$-Einheitsmatrix sind alle Eintr\"age auf der Hauptdiagonalen gleich $1$ und alle anderen
%        gleich $0$, also 
%        \begin{equation*}
%        E_{n} := \begin{pmatrix}
%                 1 & 0 & \cdots & 0 & 0 \\
%                 0 & 1 & \cdots & 0 & 0 \\
%                 \vdots & \vdots & \ddots & \vdots & \vdots \\
%                 0 & 0 & \cdots & 1 & 0 \\
%                 0 & 0 & \cdots & 0 & 1 
%                 \end{pmatrix} \in M(n;\R).
%   \end{equation*}
% \tab{Diagonalmatrizen}
%               Eine Matrix der Form
%        \begin{equation*}
%        \begin{pmatrix}
%        a_{11} & 0 & \cdots & 0 & 0 \\
%        0 & a_{22} & \cdots & 0 & 0 \\
%        \vdots & \vdots & \ddots & \vdots & \vdots \\
%        0 & 0 & \cdots & a_{n-1,n-1} & 0 \\
%        0 & 0 & \cdots & 0 & a_{nn} 
%        \end{pmatrix} \in M(n;\R)
%        \end{equation*}
%        mit $a_{ii}\in \R$ nennt man \notion{Diagonalmatrix}.
%        Hier stehen \emph{h\"ochstens} auf der Diagonalen von $0$ verschiedene Eintr\"age. 
%        Man schreibt auch kurz $\text{diag}(a_{11},a_{22},\cdots,a_{nn})$.
       
% \tab{Untere Dreiecksmatrizen}
%       Eine Matrix der Form
%        \begin{equation*}
%        \begin{pmatrix}
%        a_{11} & 0 & \cdots & 0 & 0 \\
%        a_{21} & a_{22} & \cdots & 0 & 0 \\
%        \vdots & \vdots & \ddots & \vdots & \vdots \\
%        a_{n-1,1} & a_{n-1,2} & \cdots & a_{n-1,n-1} & 0 \\
%        a_{n1} & a_{n2} & \cdots & a_{n,n-1} & a_{nn} 
%        \end{pmatrix} \in M(n;\R)
%        \end{equation*}
%        mit reellen Zahlen $a_{ij}$ nennt man \notion{untere Dreiecksmatrix} (nur unterhalb oder auf der 
%        Diagonalen dürfen die Eintr\"age ungleich $0$ sein).
% \tab{Obere Dreiecksmatrizen}
%        Analog zur unteren Dreiecksmatrix nennt man eine Matrix der Form
%        \begin{equation*}
%        \begin{pmatrix}
%        a_{11} & a_{12} & \cdots & a_{1,n-1} & a_{1n} \\
%        0 & a_{22} & \cdots & a_{2,n-1} & a_{2n} \\
%        \vdots & \vdots & \ddots & \vdots & \vdots \\
%        0 & 0 & \cdots & a_{n-1,n-1} & a_{n-1,n} \\
%        0 & 0 & \cdots & 0 & a_{nn} 
%        \end{pmatrix} \in M(n;\R)
%        \end{equation*}
%        mit reellen Zahlen $a_{ij}$ eine \notion{obere Dreiecksmatrix} (nur oberhalb oder auf der Diagonalen 
%        dürfen die Eintr\"age ungleich $0$ sein). 
% \end{tabs*}
% \end{definition}

% \begin{example}
% \begin{enumerate}
% \item Die Nullmatrix $0_n$ und die Einheitsmatrix $E_n$ sind spezielle Diagonalmatrizen. Sie
% sind auch untere und obere Dreiecksmatrizen.
% \item Jede Diagonalmatrix ist sowohl eine untere als auch eine obere Dreiecksmatrix.

% \end{enumerate}
% \end{example}

% \section{Rechnen mit quadratischen Matrizen}

% In den Abschnitten \link{matrizen-add}{Addition und Skalarmultiplikation von Matrizen} und 
% \link{matrix-mult}{Matrizenmultiplikation}
% wurden schon Matrizen addiert und multipliziert. Während bei der Addition die Größe
% der Matrizen gleich sein muss, muss bei der Multiplikation die Zeilenzahl der zweiten Matrix 
% gleich der Spaltenzahl der ersten Matrix sein. Sind $A$ und $B$ also quadratische $(n\times n)$-Matrizen mit 
% Einträgen in $\R$, so sind beide Bedingungen erfüllt, und daher ist sowohl die Summe
% \[ A+B \]
% als auch das Produkt
% \[ A\cdot B\]
% definiert. In beiden Fällen ist das Ergebnis wieder eine $(n\times n)$-Matrix.

% Natürlich gelten auch die allgemeinen \ref[matrizen][Rechenregeln für die Addition]{rule:rechenregeln} und 
% für die  \ref[matrix-mult][Matrizenmultiplikation]{rule:rechenregeln}
% in diesem speziellen Fall:

% \begin{rule}
% Auf der Menge $M(n;\R)$ der $(n\times n)$-Matrizen mit Einträgen in $\R$ sind die Addition $+$ und die 
% Multiplikation $\cdot$ definiert, die zwei Matrizen $A$ und $B$ wieder eine $(n\times n)$-Matrix, nämlich
% deren Summe $A+B$ bzw. deren Produkt $A\cdot B$ zuordnen. 
% Es gelten für alle $A,B,C\in M(n;\R)$:

%    \emph{Rechenregeln der Addition:} 
%     \begin{itemize}
%         \item $A+B=B+A$ $\quad$ (Kommutativgesetz)
%         \item $\left(A+B\right)+C=A+\left(B+C\right)$ $\quad$
%             (Assoziativgesetz)
%         \item Die Nullmatrix $0_n\in M(n;\R)$ erfüllt  $\nowrap{A+0_n=A}$ für alle $A\in M(n;\R)$
%         (neutrales Element der Addition).
%         \item Für jede Matrix $A\in M(n;\R)$ ist $A+(-A)=0_n$.
%     \end{itemize}
    
%     \\    
%     \emph{Rechenregeln der Multiplikation:} 
%     \begin{itemize}
% %        \item[(M1)] $a\cdot b=b\cdot a$ $\quad$ (Kommutativgesetz)
%         \item $A\cdot \left(B\cdot C\right) = \left(A\cdot B\right)\cdot 
%             C$ $\quad$ (Assoziativgesetz)
%         \item Die Einheitsmatrix $E_n\in  M(n;\R)$ erfüllt $A\cdot E_n=E_n\cdot A=A$
%         (neutrales Element der Multiplikation).
%     \end{itemize}
    
%     \\
%     \emph{Vertr\"aglichkeit von Addition und Multiplikation:} \\
%     \begin{itemize}
%         \item $\left(A+B\right)\cdot C=A\cdot C+B\cdot C$ $\quad$ und\\
%         $A\cdot \left(B+C\right)=A\cdot B+A\cdot C$ $\quad$
%             (Distributivgesetze)
%     \end{itemize}
% \end{rule}


% \begin{remark}
% Vergleicht man die Rechenregeln mit den \ref[koerperaxiome][Körperaxiomen]{sec:axiome},
% so stellt man fest, dass lediglich die Kommutativität der Multiplikation und die Existenz inverser
% Elemente bzgl. der Multiplikation für die Matrizen nicht gelten.

% In der Tat ist zum Beispiel für
% $A = \begin{pmatrix}
% 1 & 2 \\ 0& 1
% \end{pmatrix} \,\,\text{und }
% B = \begin{pmatrix}
% 2 & 0\\ 1&1 \end{pmatrix} \in M(2;\R) 
% $
% \[ AB=\begin{pmatrix}
% 1 & 2 \\ 0& 1
% \end{pmatrix}\cdot \begin{pmatrix}
% 2 & 0\\ 1&1 \end{pmatrix}=\begin{pmatrix} 4&2\\ 1&1\end{pmatrix}, \]
% aber 
% \[ BA=\begin{pmatrix}
% 2 & 0\\ 1&1 \end{pmatrix}\cdot\begin{pmatrix}
% 1 & 2 \\ 0& 1
% \end{pmatrix}=\begin{pmatrix} 2&4\\ 1&3\end{pmatrix}. \]

% Für die Matrix $C=\begin{pmatrix}
% 1 & 0 \\ 0& 0
% \end{pmatrix}$ wiederum gibt es keine Matrix $D$ mit $C\cdot D=E_2=\begin{pmatrix} 1&0\\ 0&1\end{pmatrix}$, denn im Produkt 
% \[ \begin{pmatrix}
% 1 & 0 \\ 0& 0
% \end{pmatrix}\cdot D \]
% ist stets die zweite Zeile gleich $(0 \ 0)$. Auch gibt es keine Matrix $D$ mit $D\cdot C=E_2$, denn im Produkt
% \[ D\cdot \begin{pmatrix}
% 1 & 0 \\ 0& 0
% \end{pmatrix} \]
% ist stets die zweite Spalte gleich $\left(\begin{smallmatrix} 0\\ 0 \end{smallmatrix}\right)$.
% \end{remark}



% \section{Invertierbare Matrizen}\label{sec:invertierbare-matrizen}

% Da es nicht für jede Matrix $A\in M(n;\R)$ eine Matrix $B\in M(n;\R)$ mit $A\cdot B=E_n$ gibt,
% erhalten solche Matrizen, für die es so ein $B$ gibt, einen besonderen Namen.

% \begin{definition}\label{def:invertierbar}
% Eine Matrix $A\in M(n;\R)$ heißt \notion{invertierbar} (oder auch \notion{regulär}), wenn es
% eine Matrix $B\in M(n;\R)$ mit $A\cdot B=E_n$ gibt.

% In diesem Fall wird die Matrix $B$ \notion{inverse Matrix} zu $A$ genannt und mit $A^{-1}$ bezeichnet.
% \end{definition}

% \begin{remark}\label{rem:links-invers}
% \begin{enumerate}
% \item Wenn $A$ invertierbar ist, dann gibt es auch nur genau eine Matrix $B$ mit $A\cdot B=E_n$, 
% weshalb es gerechtfertigt ist, von \textbf{der} inversen Matrix $A^{-1}$ von $A$ zu sprechen.\\
% Die inverse Matrix $A^{-1}$ erfüllt außerdem auch
% \[ A^{-1}\cdot A=E_n. \]
% \item Gibt es andererseits zu $A\in M(n;\R)$ eine Matrix $B\in M(n;\R)$ mit $B\cdot A=E_n$, so
% gilt auch $A\cdot B=E_n$. Man hätte also alternativ definieren können, dass $A$ invertierbar ist,
% wenn es eine Matrix $B\in M(n;\R)$ mit $B\cdot A=E_n$ gibt.
% \end{enumerate}
% Die Begründungen für diese Tatsachen werden im \link{inverse-matrix}{nächsten Abschnitt} klar, 
% wo erklärt wird, wie man die inverse Matrix berechnen kann.
% \end{remark}

% \begin{example}
% \begin{enumerate}
% \item Die Matrix $A = \begin{pmatrix}
% 1 & 2 \\ 0& 1
% \end{pmatrix} \in M(2;\R) $ ist invertierbar mit inverser Matrix
% \[ A^{-1}=\begin{pmatrix}
% 1 & -2 \\ 0& 1
% \end{pmatrix}, \]
% denn
% \[  A\cdot A^{-1}= \begin{pmatrix}
% 1 & 2 \\ 0& 1
% \end{pmatrix} \cdot \begin{pmatrix}
% 1 & -2 \\ 0& 1
% \end{pmatrix} = \begin{pmatrix}
% 1\cdot 1+2\cdot 0 & 1\cdot (-2)+2\cdot 1 \\ 0\cdot 1+1\cdot 0 & 0\cdot 2+1\cdot 1
% \end{pmatrix}= \begin{pmatrix}
% 1 & 0 \\ 0& 1
% \end{pmatrix}. \]
% \item Die Matrix $B = \begin{pmatrix}
% 3 & 2 \\ -1& 1
% \end{pmatrix} \in M(2;\R) $ ist invertierbar mit inverser Matrix
% \[ B^{-1}=\begin{pmatrix}
% 1/5 & -2/5 \\ 1/5& 3/5
% \end{pmatrix}, \]
% denn
% \[  B\cdot B^{-1}= \begin{pmatrix}
% 3 & 2 \\ -1& 1
% \end{pmatrix} \cdot \begin{pmatrix}
% 1/5 & -2/5 \\ 1/5& 3/5
% \end{pmatrix} = \begin{pmatrix}
% 3/5+2/5 & -6/5+6/5 \\ -1/5+1/5 & 2/5+3/5
% \end{pmatrix}= \begin{pmatrix}
% 1 & 0 \\ 0& 1
% \end{pmatrix}. \]
% Man sieht hier auch direkt
% \[ B^{-1}\cdot B=\begin{pmatrix}
% 1/5 & -2/5 \\ 1/5& 3/5
% \end{pmatrix} \cdot \begin{pmatrix}
% 3 & 2 \\ -1& 1
% \end{pmatrix} = \begin{pmatrix}
% 3/5+2/5 & 2/5-2/5 \\ 3/5-3/5 & 2/5+3/5
% \end{pmatrix}= \begin{pmatrix}
% 1 & 0 \\ 0& 1
% \end{pmatrix}. \]
% \end{enumerate}
% \end{example}

% Allgemeinere Beispiele sind die folgenden.

% \begin{example}
% \begin{enumerate}
% \item Die Einheitsmatrix $E_n$ ist invertierbar mit inverser Matrix $E_n$, denn
% $E_n\cdot E_n=E_n$.
% \item Eine Diagonalmatrix $D=\diag(a_{11},a_{22},\ldots, a_{nn})$ mit $a_ii\in\R$ ist genau dann invertierbar, 
% wenn alle Diagonaleinträge ungleich $0$ sind. In diesem Fall ist die inverse Matrix die Diagonalmatrix
% \[  D^{-1}=\diag(\frac{1}{a_{11}},\frac{1}{a_{22}},\ldots, \frac{1}{a_{nn}}). \]
% \end{enumerate}
% \end{example}

% \begin{block}[warning]
% Da die Matrizenmultiplikation nicht kommutativ ist, sollte die für Zahlen übliche Bruchschreibweise $\frac{a}{b}$ für $ab^{-1}$ bei Matrizen nicht verwendet werden. Die für Brüche von Zahlen geltenden Rechenregeln
% \[ \frac{a}{b}\cdot \frac{c}{d}=\frac{ac}{bd}\quad \text{und} \quad \frac{a}{b}+\frac{c}{d}=\frac{ad+bc}{bd}\]
% wären nämlich für Matrizen falsch!
% \end{block}



\end{visualizationwrapper}

\end{content}