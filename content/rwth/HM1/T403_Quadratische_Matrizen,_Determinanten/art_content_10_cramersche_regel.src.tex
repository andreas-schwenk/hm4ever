%$Id:  $
\documentclass{mumie.article}
%$Id$
\begin{metainfo}
  \name{
    \lang{de}{Cramersche Regel}
    \lang{en}{Cramer's rule}
  }
  \begin{description} 
 This work is licensed under the Creative Commons License Attribution 4.0 International (CC-BY 4.0)   
 https://creativecommons.org/licenses/by/4.0/legalcode 

    \lang{de}{Beschreibung}
    \lang{en}{}
  \end{description}
  \begin{components}
    \component{generic_image}{content/rwth/HM1/images/g_img_00_video_button_schwarz-blau.meta.xml}{00_video_button_schwarz-blau}
  \end{components}
  \begin{links}
\link{generic_article}{content/rwth/HM1/T403_Quadratische_Matrizen,_Determinanten/g_art_content_08_inverse_matrix.meta.xml}{content_08_inverse_matrix}
\link{generic_article}{content/rwth/HM1/T403_Quadratische_Matrizen,_Determinanten/g_art_content_09_determinante.meta.xml}{content_09_determinante}
\end{links}
  \creategeneric
\end{metainfo}
\begin{content}
\usepackage{mumie.ombplus}
\ombchapter{3}
\ombarticle{4}
%\usepackage{mumie.genericvisualization}

%\begin{visualizationwrapper}

\title{\lang{de}{Cramersche Regel} \lang{en}{Cramer's rule}}

\begin{block}[annotation]

  
\end{block}
\begin{block}[annotation]
  Im Ticket-System: \href{http://team.mumie.net/issues/11285}{Ticket 11285}\\
\end{block}

\begin{block}[info-box]
\tableofcontents
\end{block}

\section{\lang{de}{Lineare Gleichungssysteme mit invertierbarer Koeffizientenmatrix} 
\lang{en}{Systems of linear equations with invertible coefficient matrix}}

\lang{de}{
Die Aussagen über Invertierbarkeit von Matrizen aus den vorigen Abschnitten sollen nun
verwendet werden, um Aussagen über Lösungsmengen linearer Gleichungssysteme zu machen.

Wir betrachten also im Folgenden das lineare Gleichungssystem $Ax=b$ mit quadratischer Koeffizientenmatrix $A$, d.h. mit gleich vielen Variablen wie Gleichungen.}

\lang{en}{
We want to utilise the statements about invertibility of matrices from the previous sections to make statements about the
solution set of linear systems.

In the following we will consider the linear system $Ax=b$ with square coefficient matrix, i.e. with the same number of variables and equations. }

\begin{theorem}\label{thm:lgs-mit-quadrat-matrix}
\lang{de}{
Sei ein lineares Gleichungssystem $A  x =b$ mit $A \in M(n;\K)$, $b \in \K^n$, gegeben. Dann sind äquivalenz}
\lang{en}{
Give a linear system $A  x =b$ with $A \in M(n;\K)$, $b \in \K^n$. Then equivalent are }
\begin{enumerate}
 \item \lang{de}{Das LGS hat genau eine L\"osung.} \lang{en}{The linear system has exactly one solution.}
 \item \lang{de}{Die Matrix $A$ ist invertierbar.} \lang{en}{The matrix $A$ is invertible.}
 \item \lang{de}{Es gilt $\det(A) \neq 0 $.} \lang{en}{It holds $\det(A)\neq 0$.}
 \item \lang{de}{Die Matrix $A$ hat vollen Rang.} \lang{en}{The rank of the matrix $A$ is full.}
\end{enumerate}
\end{theorem}

\begin{proof*}
\begin{showhide}
\lang{de}{
Wir hatten schon gesehen, dass $A$ genau dann invertierbar ist, wenn sie vollen Rang (also Rang $n$) hat, 
und dass auch $\det(A) \neq 0 $ genau dann gilt, wenn $A$ vollen Rang hat.}
\lang{en}{
We already know, that $A$ is invertible if and only if the rank of $A$ is full (rank $n$). Furthermore is $\det(A) \neq 0 $ equivalent
to $A$ having full rank. }

\lang{de}{
Hat die Matrix $A$ nun vollen Rang, dann erhält man die reduzierte Stufenform der Begleitmatrix $(A\mid b)$
als $(E_n\mid \tilde{b})$ und man erhält eine eindeutige Lösung des LGS, nämlich
\[ x=\tilde{b}=A^{-1} \cdot b.\]}
\lang{en}{
If the rank of $A$ is full, we get the reduced row echelon form of the companion matrix $(A\mid b)$, which is $(I_n\mid \tilde{b})$. 
Then we get exactly one solution, namely
\[ x=\tilde{b}=A^{-1} \cdot b.\]}

\lang{de}{
Hat die Matrix $A$ keinen vollen Rang, dann besitzt die linke Seite  in der reduzierten Stufenform der Begleitmatrix weniger als 
$n$ Stufen und  enthält daher mindestens eine Nullzeile. 
Damit ist die Lösungsmenge entweder leer (wenn der entsprechende Eintrag der rechten Seite nicht $0$ ist), 
oder es gibt Lösungen und die Variablen, zu denen keine Stufen gehören, können als freie Parameter gewählt werden. 
Damit gibt es aber mehrere Lösungen.}
\lang{en}{
If the rank of $A$ is not full, then the left side of the reduced row echelon form of the companion matrix has less than
$n$ echelons and therefore at least one zero-row.
As a consequence, the solution set is either empty (if the corresponding entry on the right side is unequal to $0$) or 
there are solution and the variables without echelon can be chosen as free variables.
But then there exist several solutions.}

\lang{de}{Das LGS hat also genau dann genau eine Lösung, wenn die Matrix $A$ vollen Rang hat.}
\lang{en}{So the linear system has exactly one solution if and only if the rank of $A$ is full.}
\end{showhide}
\end{proof*}
\begin{example}
\lang{de}{
Benötigt man zu einer bestimmten invertierbaren Matrix $A\in M(n;\K)$ die Lösungen des LGS $A\cdot x=b$ zu mindestens $n$ 
verschiedenen Werten von $b$, dann ist es sinnvoll, die Inverse von $A$ zu berechnen.}
\lang{en}{
If we need the solutions of a linear system $A\cdot x=b$ with a given invertible matrix $A\in M(n;\K)$ for at least $n$ different
values of $b$, then it makes sense to determine the inverse of $A$.}
\\
\lang{de}{
Sollen etwa zu 
$A=\begin{pmatrix} 2&5\\1&3\end{pmatrix}$ die Lösungen der LGS  $A\cdot x=b_j$ für $b_1=\begin{pmatrix}1\\1\end{pmatrix}$, $b_2=\begin{pmatrix}1\\-1\end{pmatrix}$,
$b_3=\begin{pmatrix}2\\1\end{pmatrix}$ und $b_4=\begin{pmatrix}5\\-2\end{pmatrix}$ bestimmt werden,
dann erhält man mit $A^{-1}=\begin{pmatrix}3&-5\\-1&2\end{pmatrix}$ dazu die 
Lösungen $x_1=A^{-1}\cdot b_1=\begin{pmatrix}-2\\1\end{pmatrix}$, $x_2=A^{-1}\cdot b_2=\begin{pmatrix}8\\-3\end{pmatrix}$, 
$x_3=A^{-1}\cdot b_3=\begin{pmatrix}1\\0\end{pmatrix}$ und $x_4=A^{-1}\cdot b_4=\begin{pmatrix}25\\-9\end{pmatrix}$ durch einfache Matrix-Vektor-Multiplikation, 
ohne vier LGS lösen zu müssen.}
\lang{en}{
For example we want to determine the solution of the linear system $A\cdot x=b_j$ with $A=\begin{pmatrix} 2&5\\1&3\end{pmatrix}$
for $b_1=\begin{pmatrix}1\\1\end{pmatrix}$, $b_2=\begin{pmatrix}1\\-1\end{pmatrix}$,
$b_3=\begin{pmatrix}2\\1\end{pmatrix}$ und $b_4=\begin{pmatrix}5\\-2\end{pmatrix}$.
With $A^{-1}=\begin{pmatrix}3&-5\\-1&2\end{pmatrix}$ we receive the corresponding solutions $x_1=A^{-1}\cdot b_1=\begin{pmatrix}-2\\1\end{pmatrix}$, $x_2=A^{-1}\cdot b_2=\begin{pmatrix}8\\-3\end{pmatrix}$, 
$x_3=A^{-1}\cdot b_3=\begin{pmatrix}1\\0\end{pmatrix}$ und $x_4=A^{-1}\cdot b_4=\begin{pmatrix}25\\-9\end{pmatrix}$ with simple matrix-vector-multiplication
withouth solving four linear systems.}
\end{example}

\lang{de}{
Um die eindeutige Lösung des LGS $A \cdot x=b$ im Fall einer invertierbaren Matrix zu berechnen, gibt es noch eine Formel, 
die sogenannte \emph{Cramersche Regel}.
Für größere Gleichungssysteme (d.h. $n\geq 4$) ist sie im Allgemeinen unpraktisch,
weil der Rechenaufwand der Cramerschen Regel deutlich höher ist als der des Gaußalgorithmus.
Für kleine Gleichungssysteme (d.h. $n=2$ oder $3$) lässt sich die Lösung damit recht flott berechnen.}
\lang{en}{
There is another formula for calculating the unique solution of the linear system $A\cdot x=b$ for a invertible matrix.
It es called the \emph{Cramer's rule}.}
\\
\lang{de}{
Im Fall $n=2$  ist die Benutzung der Formel für die inverse Matrix (wie im obigen Beispiel)
etwa ebenso aufwändig wie die Cramerschen Regel.}
\lang{en}{
For $n=2$ the effort of the formular for the inverse matrix (like in the example above) is the same as the effort for the Cramer's rule.}
\\
\lang{de}{
Im Fall $n=3$ bedeutet die Cramersche Regel schon mehr Rechenaufwand als der Gauß-Algorithmus. 
Dass man sie mit Papier und Bleistift  trotzdem verwendet, hat einen bestechenden Grund: Bei der Cramerschen Regel  
wird erst im allerletzten Schritt eine Division durchgeführt, ansonsten nur Multiplikationen und Additionen.
Beim Gauß-Algorithmus muss im Allgemeinen schon im ersten Schritt auch eine Divison durchgeführt werden, 
was beim Kopfrechnen für viele Studierende eine Fehlerquelle darstellt.}
\lang{en}{
For $n=3$ we have a lot more calculation work with the Cramer's rule compared with the Gaussian elimination. But there is a good reason,
that we use it while calculating by hand: There is exactly one division in the Cramer's rule, which appears in the last step. Gaussian 
elimination needs division a lot earlier, sometimes even in the first step. This is a potential source of errors for a lot of students.}
\\
\lang{de}{
Übrigens liegt genau in dieser einen Division im letzten Schritt der Grund verborgen, weshalb Mathematiker diese Regel (in der Theoriebildung, nicht praktisch!)
verwenden: Die auftretenden Nenner sind allesamt Teiler der Determinante von $A$.} 
\lang{en}{
Incidentally, the reason why mathematicians use this rule (in theory, not in practice!) is exactly this division in the last step.
The denominators that occur are all divisors of the determinant of $A$.}

\begin{rule}[\lang{de}{Cramersche Regel} \lang{en}{Cramer's rule}] \label{cramersche_regel}
\lang{de}{Sei $A \in M(n;\K)$ invertierbar, $b \in \K^n$, und $A \cdot x=b$ das zugeh\"orige LGS. 
Schreibt man $x=\left(\begin{smallmatrix}
x_1\\ \vdots \\ x_n
\end{smallmatrix}\right)$ und bezeichnet f\"ur alle $k \in \{ 1, \ldots ,n \}$ mit 
$A_{k|b}$ die Matrix, die aus $A$ entsteht, indem man die $k$-te Spalte von $A$ durch $b$ ersetzt, so ist die eindeutig bestimmte L\"osung $x$ von $A \cdot x =b$
gegeben durch
\[
x_k = \frac{\det(A_{k|b})}{\det(A)} \text{ f\"ur alle } k \in {\{ 1, \ldots ,n \} }.
\]}
\lang{en}{Let $A \in M(n;\K)$ be invertible, $b \in \K^n$, and $A \cdot x=b$ the corresponding linear system. 
If we write $x=\left(\begin{smallmatrix}
x_1\\ \vdots \\ x_n
\end{smallmatrix}\right)$ and denote for all $k \in \{ 1, \ldots ,n \}$ $A_{k|b}$ for the matrix, that results from $A$
by exchanging the $k$th column $A$ with $b$, then the unique solution $x$ of $A\cdot x=b$ is given by
\[
x_k = \frac{\det(A_{k|b})}{\det(A)} \text{ for all } k \in {\{ 1, \ldots ,n \} }.
\]}
\end{rule}


\begin{example}\label{ex:cramer_LGS}
\begin{tabs*}[\initialtab{0}]
\tab{\lang{de}{Beispiel 1} \lang{en}{1. Example}}
\lang{de}{Wir betrachten das lineare Gleichungssystem}
\lang{en}{We consider the linear system}
\[ \begin{mtable}[\cellaligns{ccrcrcrcr}]
\text{(I)}&&x_{1}&+&2x_{2}&+&x_{3}&=&4\\
\text{(II)}&&x_{1}&-&x_{2}&+&\frac{3}{2}x_{3}&=&-7\\
\text{(III)}&\qquad-&4x_{1}&+&2x_{2}&&&=&-2.
\end{mtable} \]
\begin{incremental}[\initialsteps{0}]

\step
\lang{de}{
Es hat als Koeffizientenmatrix
$ A=\begin{pmatrix} 1 & 2 & 1 \\ 1 & -1 & \frac{3}{2} \\ -4 & 2 & 0\end{pmatrix} $
und als rechte Seite $b=\begin{pmatrix} 4 \\ -7 \\ -2 \end{pmatrix} $.
Zunächst einmal berechnet man mit der Regel von Sarrus
\begin{eqnarray*} \det(A)&=& 1\cdot (-1)\cdot 0+2\cdot\frac{3}{2}\cdot (-4)+1\cdot 1\cdot 2-(-4)\cdot (-1)\cdot 1
-2\cdot \frac{3}{2}\cdot 1-0\cdot 1\cdot 2\\
&=& 0-12+2-4-3-0=-17.\end{eqnarray*}}
\lang{en}{
The corresponding coefficient matrix is
$ A=\begin{pmatrix} 1 & 2 & 1 \\ 1 & -1 & \frac{3}{2} \\ -4 & 2 & 0\end{pmatrix} $
and the right side is $b=\begin{pmatrix} 4 \\ -7 \\ -2 \end{pmatrix} $.
First of all we calculate $\det(A)$ with the rule of Sarrus
\begin{eqnarray*} \det(A)&=& 1\cdot (-1)\cdot 0+2\cdot\frac{3}{2}\cdot (-4)+1\cdot 1\cdot 2-(-4)\cdot (-1)\cdot 1
-2\cdot \frac{3}{2}\cdot 1-0\cdot 1\cdot 2\\
&=& 0-12+2-4-3-0=-17.\end{eqnarray*}}
\lang{de}{Die Determinante ist also ungleich $0$ und daher besitzt das LGS eine eindeutige Lösung, die wir im
Folgenden mit der Cramerschen Regel berechnen werden.}
\lang{en}{The determinant is unequal to $0$ and the linear system has a unique solution. We will calculate this in the following
using the Cramer's rule.}

\step
\lang{de}{
Dazu benötigen wir die Matrizen $A_{1|b}$, $A_{2|b}$
und $A_{3|b}$ bzw. ihre Determinanten. Die Matrix $A_{1|b}$ erhält man aus der Matrix $A$, indem man die
erste Spalte durch den Spaltenvektor $b$ ersetzt. Also gilt:
\[
\det(A_{1|b}) = \det \Big(\begin{pmatrix} 4 & 2 & 1 \\ -7 & -1 & \frac{3}{2} \\ -2 & 2 & 0\end{pmatrix}\Big)
= 0+(-6)+(-14)-2-12-0=-34 \]
und daher 
\[ x_1=\frac{\det(A_{1|b})}{\det(A)}=\frac{-34}{-17}=2.\]
Entsprechend berechnen wir}
\lang{en}{
We need the matrices $A_{1|b}$, $A_{2|b}$ and $A_{3|b}$ or rather their determinants. The matrix $A_{1|b}$ 
is the result of exchanging the first column of $A$ with the column vector $b$. We have:
\[
\det(A_{1|b}) = \det \Big(\begin{pmatrix} 4 & 2 & 1 \\ -7 & -1 & \frac{3}{2} \\ -2 & 2 & 0\end{pmatrix}\Big)
= 0+(-6)+(-14)-2-12-0=-34 \]
and therefore
\[ x_1=\frac{\det(A_{1|b})}{\det(A)}=\frac{-34}{-17}=2.\]
Analogously we calculate}
\begin{eqnarray*}
\det(A_{2|b}) &=& \det \Big(\begin{pmatrix} 1 & 4 & 1 \\ 1 & -7 & \frac{3}{2} \\ -4 & -2 & 0\end{pmatrix}\Big)
= 0+(-24)+(-2)-28-(-3)-0=-51, \\
\det(A_{3|b}) &=& \det \Big(\begin{pmatrix} 1 & 2 & 4 \\ 1 & -1 & -7 \\ -4 & 2 & -2\end{pmatrix}\Big)
= 2+56+8-16-(-14)-(-4)=68.
\end{eqnarray*}
\lang{de}{
Damit erhält man weiter
\[  x_2=\frac{-51}{-17}=3\quad \text{und}\quad x_3=\frac{68}{-17}=-4.\]}
\lang{en}{
With that we get
\[  x_2=\frac{-51}{-17}=3\quad \text{und}\quad x_3=\frac{68}{-17}=-4.\]}
\step
\lang{de}{
Die Lösungsmenge besteht also aus der eindeutigen Lösung
\[ \left( \begin{smallmatrix}x_1\\ x_2\\ x_3\end{smallmatrix}\right)
=\left( \begin{smallmatrix}2\\ 3\\ -4\end{smallmatrix}\right). \]}
\lang{en}{
The solutions set consists of the unique solution
\[ \left( \begin{smallmatrix}x_1\\ x_2\\ x_3\end{smallmatrix}\right)
=\left( \begin{smallmatrix}2\\ 3\\ -4\end{smallmatrix}\right). \]}
\end{incremental}

\tab{\lang{de}{Beispiel 2} \lang{en}{2. Example}}
\begin{incremental}[\initialsteps{1}]
\step
\lang{de}{
Es sei $B=\begin{pmatrix} 0&i&i\\i&0&i\\0&i&0\end{pmatrix}\in M(3;\C)$ und $c=\begin{pmatrix}1\\1\\1\end{pmatrix}$.
Wir lösen das LGS $ Ax=c$ mit Hilfe der Cramerschen Regel.}
\lang{en}{
Given is $B=\begin{pmatrix} 0&i&i\\i&0&i\\0&i&0\end{pmatrix}\in M(3;\C)$ and $c=\begin{pmatrix}1\\1\\1\end{pmatrix}$.
We solve the linear system $ Ax=c$ with the help of the Cramer's rule.}
\step
\lang{de}{
Für die Determinanten finden wir mit der Regel von Sarrus zunächst
$\det(B)=0+0+i^3-0-0-0=-i\neq 0$, weshalb wir die Cramersche Regel anwenden dürfen,
und weiter
\[\det(B_{1|c})=\det\Big(\begin{pmatrix} 1&i&i\\1&0&i\\1&i&0\end{pmatrix}\Big)=i^2+i^2-i^2=-1,\]
\[\det(B_{2|c})=\det\Big(\begin{pmatrix} 0&1&i\\i&1&i\\0&1&0\end{pmatrix}\Big)=i^2=-1\]
und
\[\det(B_{3|c})=\det\Big(\begin{pmatrix} 0&i&1\\i&0&1\\0&i&1\end{pmatrix}\Big)=i^2-i^2=0.\]}
\lang{en}{
The determinant of $B$ is $\det(B)=0+0+i^3-0-0-0=-i\neq 0$ (calculated with the help of the rule of Sarrus), 
which is why we may use the Cramer's rule.
Furtheron we have
\[\det(B_{1|c})=\det\Big(\begin{pmatrix} 1&i&i\\1&0&i\\1&i&0\end{pmatrix}\Big)=i^2+i^2-i^2=-1,\]
\[\det(B_{2|c})=\det\Big(\begin{pmatrix} 0&1&i\\i&1&i\\0&1&0\end{pmatrix}\Big)=i^2=-1\]
and
\[\det(B_{3|c})=\det\Big(\begin{pmatrix} 0&i&1\\i&0&1\\0&i&1\end{pmatrix}\Big)=i^2-i^2=0.\]}
\step
\lang{de}{
Also ist 
\[x=\frac{1}{-i}\begin{pmatrix}-1\\-1\\0\end{pmatrix}=\begin{pmatrix}-i\\-i\\0\end{pmatrix}\]
die eindeutig bestimmte Lösung des LGS.}
\lang{en}{
It is
\[x=\frac{1}{-i}\begin{pmatrix}-1\\-1\\0\end{pmatrix}=\begin{pmatrix}-i\\-i\\0\end{pmatrix}\]
the unique solution of the linear system.}
\end{incremental}
\end{tabs*}
\end{example}


\begin{quickcheck}
\text{\lang{de}{Es sei $A=\begin{pmatrix}2&-1&1\\0&1&0\\0&0&3\end{pmatrix}$. Welcher der folgenden Ausdrücke
bestimmt die zweite Komponente der Lösung $x=\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix}$ des LGS $A\cdot x=\begin{pmatrix}4\\4\\4\end{pmatrix}$?}
\lang{en}{Given is $A=\begin{pmatrix}2&-1&1\\0&1&0\\0&0&3\end{pmatrix}$. Which of the following terms
determines the second componant of the solution $x=\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix}$ of the linear system $A\cdot x=\begin{pmatrix}4\\4\\4\end{pmatrix}$?}}
\begin{choices}{unique}
\begin{choice}
\text{$x_2=\frac{1}{6}\det\Big( \left( \begin{smallmatrix} 2&4&1\\0&4&0\\0&4&3\end{smallmatrix}\right)\Big)$}
\solution{true}
\end{choice}
\begin{choice}
\text{$x_2=\frac{1}{6}\det\Big( \left( \begin{smallmatrix} 2&1&4\\0&0&4\\0&3&4\end{smallmatrix}\right)\Big)$}
\solution{false}
\end{choice}
\begin{choice}
\text{$x_2=\frac{1}{6}\det\Big( \left( \begin{smallmatrix} 2&-1&1&4\\0&1&0&4\\0&0&3&4\end{smallmatrix}\right)\Big)$}
\solution{false}
\end{choice}
\end{choices}
\explanation{\lang{de}{Der letzte Ausdruck ist gar nicht wohldefiniert, denn Determinanten kann man nur von quadratischen Matrizen bilden.
Beim zweiten Ausdruck ist zwar die zweite Spalte gestrichen, aber der Vektor $b$ wurde nur hinten angehängt. Er gehört hingegebn wie im ersten Ausdruck in die zweite Spalte.}
\lang{en}{The last term is not well-defined, because determinants can only be calculated for square matrices.
The second term has the second column removed, but the vector $b$ is only added at the end, but he belongs into the second column, like in the first term.}}
\end{quickcheck}




\section{\lang{de}{Berechnung der inversen Matrix mit Cramerscher Regel} \lang{en}{Calculation of the inverse matrix with Cramer's rule}}

\lang{de}{Da man zu einer invertierbaren Matrix $A$ die Spalten der inversen Matrix $A^{-1}$ als
Lösungen von Gleichungssystemen bekommt, lässt sich auch die inverse Matrix mit Hilfe der
Cramerschen Regel berechnen.}
\lang{en}{
The columns of the inverse matrix $A^{-1}$ of a invertible matrix $A$ are solutions of linear systems. Therefore we can calculate
the inverse matrix with Cramer's rule.
}


\begin{rule}[\lang{de}{Cramersche Regel und inverse Matrizen} \lang{en}{Cramer's rule and inverse matrices}]\label{rule:inverse_via_cramer}
\lang{de}{Sei $A \in M(n;\K)$ invertierbar. Mit Hilfe der Cramerschen Regel l\"asst sich die inverse Matrix berechnen, indem man f\"ur $b$ in der Gleichung $Ax=b$
der Reihe nach die Vektoren 
\[
e_1 := \begin{pmatrix} 1 \\ 0 \\ 0 \\ \vdots \\ 0 \\ 0 \end{pmatrix} , \ e_2 := \begin{pmatrix} 0 \\ 1 \\ 0 \\ \vdots \\ 0 \\ 0 \end{pmatrix}, \ \cdots \ , e_m := \begin{pmatrix} 0 \\ 0 \\ 0 \\ \vdots \\ 0 \\ 1 \end{pmatrix} \in \K^n,
\]
einsetzt und die erhaltenen L\"osungen $x$ (abh\"angig von $e_i$, $1 \leq i \leq n$) nebeneinander in eine Matrix schreibt.}
\lang{en}{Let $A \in M(n;\K)$ be invertible. With the help of Cramer's rule, we can calculate the inverse matrix
by inserting the following vectors (in this order) for $b$ in the equation $Ax=b$:
\[
e_1 := \begin{pmatrix} 1 \\ 0 \\ 0 \\ \vdots \\ 0 \\ 0 \end{pmatrix} , \ e_2 := \begin{pmatrix} 0 \\ 1 \\ 0 \\ \vdots \\ 0 \\ 0 \end{pmatrix}, \ \cdots \ , e_m := \begin{pmatrix} 0 \\ 0 \\ 0 \\ \vdots \\ 0 \\ 1 \end{pmatrix} \in \K^n,
\]
Then we write the received solutions $x$ (depending on $e_i$, $1 \leq i \leq n$) next to each other into a matrix.}

\lang{de}{
Explizit ergibt sich dabei der $(i,j)$-Eintrag von $A^{-1}$ als
\[   (-1)^{i+j} \frac{\det(A_{ji})}{\det(A)}, \]
wobei $A_{ji}$ die $(n-1)\times (n-1)$-Matrix ist, die man aus $A$ durch Streichen der $j$-ten Zeile und $i$-ten Spalte erhält.}
\lang{en}{
Explizitly, the $(i,j)$-entry of $A^{-1}$ results as
\[   (-1)^{i+j} \frac{\det(A_{ji})}{\det(A)}, \]
with $A_{ji}$ as the $(n-1)\times (n-1)$-Matrix with removed $j$th row and $i$th column (in $A$).}
\end{rule}

\begin{proof*}
\lang{de}{
Wir benutzen die Cramersche Regel und berechnen die auftretenden Determinanten durch Laplace-Entwicklung.}
\lang{en}{
We utilise Cramer's rule and determine the occuring determinants with Laplace-expansion.}

\begin{incremental}[\initialsteps{0}]
\step
\lang{de}{
Mit der Cramerschen Regel für die Lösung eines linearen Gleichungssystems erhält man für den 
$(i,j)$-Eintrag von $A^{-1}$ zunächst den Wert
\[  \frac{\det(A_{i|e_j})}{\det(A)}. \]}
\lang{en}{
With the help of Cramer's rule we get for the $(i,j)$-entry of $A^{-1}$ first of all the value
\[  \frac{\det(A_{i|e_j})}{\det(A)}. \]}

\step
\lang{de}{
Die Matrix $A_{i|e_j}$ entsteht aus $A$, indem man die $i$-te \emph{Spalte} durch $e_j$ ersetzt.
Entwickeln wir ihre Determinante mit dem \ref[content_09_determinante][Laplaceschen Entwicklungssatz]{rule:Laplace}  nach der $i$-ten Spalte,
so ist darin nur der $j$-te Summand von null verschieden. Er besteht aus dem Produkt des Vorzeichen $(-1)^{i+j}$ mit
der Determinante der Matrix, die aus $A$ durch Streichen der $i$-ten \emph{Spalte} und $j$-ten \emph{Zeile} entsteht,
\[\det(A_{i|e_j})=(-1)^{i+j}\det(A_{ji}).\]}
\lang{en}{
The matrix $A_{i|e_j}$ results from $A$, by replacing the $i$th \emph{column} with $e_j$.
If we determine the determinant with \ref[content_09_determinante][Laplace-expansion]{rule:Laplace} along with the $i$th column,
only the $j$th summand is unequal to $0$. It consists of the product of the sign $(-1)^{i+j}$ and the determinant of the matrix, that
results from crossing out the $i$th \emph{column} and the $j$th \emph{row},
\[\det(A_{i|e_j})=(-1)^{i+j}\det(A_{ji}).\]}
% Vertauscht man nun aber zur Berechnung von $\det(A_{i|e_j})$ die $i$-te Zeile nacheinander mit den darüberliegenden
% und dann die $j$-te Spalte nacheinander mit den links davon liegenden, so erhält man eine Block-Dreiecksmatrix der Form
% \[  \begin{pmatrix} 1 & * \\ 0 & B\end{pmatrix},\]
% wobei $*$ irgendeine $1\times (n-1)$-Matrix (=Zeilenvektor) ist und $0$ die $(n-1)\times 1$-Nullmatrix. Die Matrix $B$
% ist jedoch nichts anderes als die Matrix $A_{ji}$, die man aus $A$ durch Streichen der $j$-ten Zeile und 
% $i$-ten Spalte erhält.
% \step
% Insgesamt wurden $i-1$ Zeilenvertauschungen und $j-1$ Spaltenvertauschungen vorgenommen. Also ist
% \[  \det(A_{i|e_j})=(-1)^{i-1+j-1}\cdot \det\big( \begin{pmatrix} 1 & * \\ 0 & A_{ji}\end{pmatrix} \big)
% = (-1)^{i+j}\cdot 1\cdot \det(A_{ji}), \]
% wie behauptet.
\end{incremental}
\end{proof*}




\begin{example}
\begin{tabs*}[\initialtab{0}]
\tab{\lang{de}{Beispiel 1} \lang{en}{1. Example}}
\lang{de}{
Wir betrachten wieder die Matrix $ A=\begin{pmatrix} 1 & 2 & 1 \\ 1 & -1 & \frac{3}{2} \\ -4 & 2 & 0\end{pmatrix} $
aus  Beispiel \ref{ex:cramer_LGS}. Deren Determinante war $\det(A)=-17\neq 0$. Die Matrix ist also invertierbar und wir
können mit der Cramerschen Regel die inverse Matrix berechnen.}
\lang{en}{
We consider again the matrix $ A=\begin{pmatrix} 1 & 2 & 1 \\ 1 & -1 & \frac{3}{2} \\ -4 & 2 & 0\end{pmatrix} $
from the example \ref{ex:cramer_LGS}. Its determinant was $\det(A)=-17\neq 0$. So the matrix is invertible
and we can calculate the inverse matrix with Cramer's rule.}
\begin{incremental}[\initialsteps{0}]

\step
\lang{de}{
Dazu müssen wir also die Determinanten der Teilmatrizen berechnen, die man erhält, wenn man eine Zeile und eine Spalte
streicht. Für den $(1,1)$-Eintrag von $A^{-1}$ benötigen wir also
\[ \det(A_{11})=\det\big( \begin{pmatrix}-1 & \frac{3}{2} \\ 2 & 0 \end{pmatrix} \big)
=-1\cdot 0-2\cdot \frac{3}{2}=-3,\]
und erhalten den Eintrag als
\[ (-1)^{1+1}\cdot \frac{\det(A_{11})}{\det(A)}=1\cdot \frac{-3}{-17}=\frac{3}{17}.\]}
\lang{en}{
For that we need to calculate the determinants of the Submatrix, that results from removing one row and one column.
For the $(1,1)$-entry of $A^{-1}$ we require
\[ \det(A_{11})=\det\big( \begin{pmatrix}-1 & \frac{3}{2} \\ 2 & 0 \end{pmatrix} \big)
=-1\cdot 0-2\cdot \frac{3}{2}=-3,\]
and receive the entry as
\[ (-1)^{1+1}\cdot \frac{\det(A_{11})}{\det(A)}=1\cdot \frac{-3}{-17}=\frac{3}{17}.\]}

\step
\lang{de}{
Für den $(1,2)$-Eintrag benötigen wir die Matrix $A_{21}$, bei der die zweite Zeile und die erste Spalte von $A$
gestrichen wurden, also $A_{21}=\left(\begin{smallmatrix}2 & 1 \\ 2 & 0\end{smallmatrix}\right)$.
Dann erhalten wir als $(1,2)$-Eintrag den Wert
\[ (-1)^{1+2}\cdot \frac{\det(A_{21})}{\det(A)}=-1\cdot \frac{-2}{-17}=-\frac{2}{17}. \]}
\lang{en}{
For the $(1,2)$-entry we require the matrix $A_{21}$ where the second row and the first column of $A$ were removed, 
so $A_{21}=\left(\begin{smallmatrix}2 & 1 \\ 2 & 0\end{smallmatrix}\right)$.
The we get for the value of the $(1,2)$-entry
\[ (-1)^{1+2}\cdot \frac{\det(A_{21})}{\det(A)}=-1\cdot \frac{-2}{-17}=-\frac{2}{17}. \]}
\step
\lang{de}{
Entsprechend berechnet man die anderen Einträge und erhält
\begin{eqnarray*} A^{-1} &=&\frac{1}{\det(A)}\cdot
\begin{pmatrix} \det(A_{11}) & -\det(A_{21}) &\det(A_{31})\\
-\det(A_{12}) &\det(A_{22}) & -\det(A_{32})\\
\det(A_{13}) & -\det(A_{23}) &\det(A_{33})
  \end{pmatrix}\\
&=& -\frac{1}{17}\cdot  \begin{pmatrix} -3 & 2 & 4\\ -6 & 4 & -\frac{1}{2}\\ -2 & -10 & -3
  \end{pmatrix}=\frac{1}{17}\cdot \begin{pmatrix} 3 & -2 & -4\\ 6 & -4 & \frac{1}{2}\\ 2 & 10 & 3
  \end{pmatrix}. \end{eqnarray*}}
  \lang{en}{
  The other entries are calculated accordingly and it yields
\begin{eqnarray*} A^{-1} &=&\frac{1}{\det(A)}\cdot
\begin{pmatrix} \det(A_{11}) & -\det(A_{21}) &\det(A_{31})\\
-\det(A_{12}) &\det(A_{22}) & -\det(A_{32})\\
\det(A_{13}) & -\det(A_{23}) &\det(A_{33})
  \end{pmatrix}\\
&=& -\frac{1}{17}\cdot  \begin{pmatrix} -3 & 2 & 4\\ -6 & 4 & -\frac{1}{2}\\ -2 & -10 & -3
  \end{pmatrix}=\frac{1}{17}\cdot \begin{pmatrix} 3 & -2 & -4\\ 6 & -4 & \frac{1}{2}\\ 2 & 10 & 3
  \end{pmatrix}. \end{eqnarray*}}
\end{incremental}

\tab{\lang{de}{Beispiel 2} \lang{en}{2. Example}}
\lang{de}{
Wir berechnen auch die inverse Matrix zu
$B=\begin{pmatrix} 0&i&i\\i&0&i\\0&i&0\end{pmatrix}\in M(3;\C)$ mit $\det(B)=-i\neq 0$
aus Beispiel \ref{ex:cramer_LGS} mit Hilfe der Cramerschen Regel.}
\lang{en}{
We also calculate the inverse matrix of
$B=\begin{pmatrix} 0&i&i\\i&0&i\\0&i&0\end{pmatrix}\in M(3;\C)$ with $\det(B)=-i\neq 0$
from example \ref{ex:cramer_LGS} using Cramer's rule.}
\begin{incremental}[\initialsteps{0}]
\step
\lang{de}{
Zunächst bestimmen wir die Determinanten der Teilmatrizen $B_{ij}$, die durch Streichen der $i$-ten Zeile 
und der $j$-ten Spalte entstehen:}
\lang{en}{
First of all we determine the determinants of the submatrices $B_{ij}$, which result from removing the $i$rh row and
the $j$th column:}
\begin{align*}
\det(B_{11})\:&=&\: \det\big( \begin{pmatrix}0&i\\i&0 \end{pmatrix} \big)=-i^2=1\\
\det(B_{12})\:&=&\: \det\big( \begin{pmatrix}i&i\\0&0 \end{pmatrix} \big)= 0\\
\det(B_{13})\:&=&\: \det\big( \begin{pmatrix} i&0\\0&i\end{pmatrix} \big)= i^2=-1\\
\det(B_{21})\:&=&\: \det\big( \begin{pmatrix} i&i\\i&0\end{pmatrix} \big)= 1\\
\det(B_{22})\:&=&\: \det\big( \begin{pmatrix} 0&i\\0&0\end{pmatrix} \big)= 0\\
\det(B_{23})\:&=&\: \det\big( \begin{pmatrix} 0&i\\0&i\end{pmatrix} \big)= 0\\
\det(B_{31})\:&=&\: \det\big( \begin{pmatrix} i&i\\0&i\end{pmatrix} \big)= -1\\
\det(B_{32})\:&=&\: \det\big( \begin{pmatrix} 0&i\\i&i\end{pmatrix} \big)= 1\\
\det(B_{33})\:&=&\: \det\big( \begin{pmatrix} 0&i\\i&0\end{pmatrix} \big)= 1 .
\end{align*}
\step

\lang{de}{
Aus denen ergibt sich der $(j,i)$-te Eintrag von $B^{-1}$ als $(-1)^{i+j}\cdot i\cdot \det(B_{ij})$, also
\[B=\begin{pmatrix}i&-i&-i\\0&0&-i\\-i&0&i\end{pmatrix}.\]}
\lang{en}{
The $(i,j)$-entry of $B^{-1}$ results from the determinants as $(-1)^{i+j}\cdot i\cdot \det(B_{ij})$, so
\[B=\begin{pmatrix}i&-i&-i\\0&0&-i\\-i&0&i\end{pmatrix}.\]}
\step 
\lang{de}{
Eine Erleichterung der Arbeit könnte man hier übrigens erreichen, indem man sich des Faktors $i$
jeder Komponente von $B$ erst einmal entledigt,
 $B=i\cdot\begin{pmatrix}0&1&0\\1&0&1\\0&1&0\end{pmatrix}$. Dann ist nämlich
\[B^{-1}=\frac{1}{i}\cdot \begin{pmatrix}0&1&0\\1&0&1\\0&1&0\end{pmatrix}^{-1}.\]}
\lang{en}{
We can relieve ourself a little, by removing the factor $i$ in each component of $B$,
 $B=i\cdot\begin{pmatrix}0&1&0\\1&0&1\\0&1&0\end{pmatrix}$. Then we have
\[B^{-1}=\frac{1}{i}\cdot \begin{pmatrix}0&1&0\\1&0&1\\0&1&0\end{pmatrix}^{-1}.\]}
\end{incremental}
\end{tabs*}
\end{example}  
  
\begin{example}
\lang{de}{
Mit Hilfe der Cramerschen Regel erhalten wir die  \ref[content_08_inverse_matrix][uns bekannte Formel]{rule:inverse-2x2}  für die inverse Matrix einer $( \times 2)$-Matrix.}
\lang{en}{
With the help of Cramer's rule we receive the \ref[content_08_inverse_matrix][formula we know]{rule:inverse-2x2} for the inverse matrix of a $(2\times 2)$-matrix.
}
\begin{incremental}[\initialsteps{0}]
\step
\lang{de}{
Gegeben sei also die Matrix $A= \begin{pmatrix}a &  b \\ c & d\end{pmatrix}$ mit Einträgen $a,b,c,d \in \K$.
Wir setzen natürlich voraus, dass $A$ invertierbar ist, d.h. $\det(A) \neq 0$.}
\lang{en}{Given is the matrix $A= \begin{pmatrix}a &  b \\ c & d\end{pmatrix}$ with entries $a,b,c,d \in \K$.
We assume, that $A$ is invertible, namely $\det(A)\neq 0$.}
\step
\lang{de}{
Da wir beim Streichen einer Zeile und Spalte eine $1 \times 1$ Matrix, also eine Zahl, erhalten,
liefert die Cramersche Regel
\[
A^{-1} = \begin{pmatrix}\frac{d}{\det(A)} & - \frac{b}{\det(A)} \\ -\frac{c}{\det(A)} & \frac{a}{\det(A)}\end{pmatrix}
= \frac{1}{\det(A)} \cdot \begin{pmatrix} d & -b \\ -c & a\end{pmatrix} = \frac{1}{ad-bc}\begin{pmatrix}d & -b \\ -c & a\end{pmatrix}.
\]}
\lang{en}{
After crossing out a row and a columns we end up with a $(1\times 1)$-matrix, so a number. Therefore Cramer's rule gives us
\[
A^{-1} = \begin{pmatrix}\frac{d}{\det(A)} & - \frac{b}{\det(A)} \\ -\frac{c}{\det(A)} & \frac{a}{\det(A)}\end{pmatrix}
= \frac{1}{\det(A)} \cdot \begin{pmatrix} d & -b \\ -c & a\end{pmatrix} = \frac{1}{ad-bc}\begin{pmatrix}d & -b \\ -c & a\end{pmatrix}.
\]}
\end{incremental}
\end{example}

\lang{de}{
Das folgende Video fasst das vorliegende Kapitel zusammen.
\floatright{\href{https://api.stream24.net/vod/getVideo.php?id=10962-2-10881&mode=iframe&speed=true}{\image[75]{00_video_button_schwarz-blau}}}}





\end{content}