%$Id:  $
\documentclass{mumie.article}
%$Id$
\begin{metainfo}
  \name{
    \lang{de}{Invertierbare Matrizen und Inverse}
    \lang{en}{Invertible matrices and inverse matrices}
  }
  \begin{description} 
 This work is licensed under the Creative Commons License Attribution 4.0 International (CC-BY 4.0)   
 https://creativecommons.org/licenses/by/4.0/legalcode 

    \lang{de}{Beschreibung}
    \lang{en}{}
  \end{description}
  \begin{components}
    \component{generic_image}{content/rwth/HM1/images/g_img_00_Videobutton_schwarz.meta.xml}{00_Videobutton_schwarz}
    \component{generic_image}{content/rwth/HM1/images/g_img_00_video_button_schwarz-blau.meta.xml}{00_video_button_schwarz-blau}
  \end{components}
  \begin{links}
    \link{generic_article}{content/rwth/HM1/T112neu_Lineare_Gleichungssysteme/g_art_content_41_gauss_verfahren.meta.xml}{content_41_gauss_verfahren1}
    \link{generic_article}{content/rwth/HM1/T111neu_Matrizen/g_art_content_43_matrizenmultiplikation.meta.xml}{content_43_matrizenmultiplikation}
    \link{generic_article}{content/rwth/HM1/T403_Quadratische_Matrizen,_Determinanten/g_art_content_08_inverse_matrix.meta.xml}{content_08_inverse_matrix}
    \link{generic_article}{content/rwth/HM1/T112neu_Lineare_Gleichungssysteme/g_art_content_45_matrixrang.meta.xml}{content_45_matrixrang}
    \link{generic_article}{content/rwth/HM1/T403_Quadratische_Matrizen,_Determinanten/g_art_content_09_determinante.meta.xml}{gauss-verfahren}
    \link{generic_article}{content/rwth/HM1/T402_Lineare_Gleichungssysteme/g_art_content_06_umformungen_rang.meta.xml}{umformungen}
    \link{generic_article}{content/rwth/HM1/T403_Quadratische_Matrizen,_Determinanten/g_art_content_07_quadratische_matrizen.meta.xml}{quadr-matrizen}
    \link{generic_article}{content/rwth/HM1/T403_Quadratische_Matrizen,_Determinanten/g_art_content_09_determinante.meta.xml}{determinante}
    \link{generic_article}{content/rwth/HM1/T111neu_Matrizen/g_art_content_44_transponierte_matrix.meta.xml}{transponierte}
  \end{links}
  \creategeneric
\end{metainfo}
\begin{content}
\usepackage{mumie.ombplus}
\ombchapter{3}
\ombarticle{2}
\usepackage{mumie.genericvisualization}

\begin{visualizationwrapper}

\title{\lang{de}{Invertierbare Matrizen und Inverse} \lang{en}{Invertible matrices and inverse matrices}}

\begin{block}[annotation]
 
  
\end{block}
\begin{block}[annotation]
  Im Ticket-System: \href{http://team.mumie.net/issues/11283}{Ticket 11283}\\
\end{block}

\begin{block}[info-box]
\tableofcontents
\end{block}

\lang{de}{
Im \link{quadr-matrizen}{letzten Abschnitt} haben wir invertierbare Matrizen definiert
 als diejenigen Matrizen $A\in M(n;\K)$, für die es eine Matrix $B$ mit $A\cdot B=E_n$ gibt.
Die Matrix $B$ haben wir dann \emph{inverse Matrix zu $A$} genannt und mit $A^{-1}$ bezeichnet.

In diesem Abschnitt beschäftigen wir uns näher mit der Invertierbarkeit. 
Insbesondere geben wir einen Algorithmus an, mit dem man die inverse Matrix $A^{-1}$ bestimmen kann, sofern sie existiert.}

\lang{en}{
In the \link{quadr-matrizen}{last section} we defined invertible matrices as those matrices $A\in M(n;\K)$, for which there is a matrix $B$ 
with $A\cdot B=I_n$.
We then called the matrix $B$ the \emph{inverse matrix of $A$} and denote it with $A^{-1}$.

In this section we will have a closer look on the invertibility.
 
In particular, we give an algorithm to determine the inverse matrix $A^{-1}$, in case $A$ is invertible.}

\section{\lang{de}{Berechnung der inversen Matrix} \lang{en}{Calculation of the inverse matrix}}\label{sec:berechnung}

\lang{de}{
Ist eine quadratische Matrix $A\in M(n;\K)$ gegeben, so müssen wir erst einmal bestimmen, ob $A$ invertierbar ist, und in diesem Fall dann die Einträge der inversen Matrix $A^{-1}$ angeben.

Nehmen wir trotzdem zunächst an, dass $A$ invertierbar ist, und $B$ eine/die Matrix mit $A\cdot B=E_n$ ist.
Dann ist die erste Spalte von $B$ aber eine Lösung des LGS
\[ A\cdot \begin{pmatrix} x_1\\ x_2\\ \vdots \\ x_n
\end{pmatrix} = \begin{pmatrix} 1\\ 0\\  \vdots \\ 0
\end{pmatrix}.\]}

\lang{en}{
For a given matrix $A\in M(n;\K)$, first of all we need to decide whether $A$ is invertible. If so, then we need to find the entries of the inverse matrix $A^{-1}$.

Supposing, $A$ is invertible and $B$ is a/the matrix with $A\cdot B=I_n$.
The first column of $B$ is a solution of the linear system
\[ A\cdot \begin{pmatrix} x_1\\ x_2\\ \vdots \\ x_n
\end{pmatrix} = \begin{pmatrix} 1\\ 0\\  \vdots \\ 0
\end{pmatrix}.\]}

\lang{de}{
Es ist also
\[ A\cdot \begin{pmatrix} b_{11}\\ b_{21}\\ \vdots \\ b_{n1}
\end{pmatrix} = \begin{pmatrix} 1\\ 0\\  \vdots \\ 0
\end{pmatrix}.\]}
\lang{en}{
Therefore we have
\[ A\cdot \begin{pmatrix} b_{11}\\ b_{21}\\ \vdots \\ b_{n1}
\end{pmatrix} = \begin{pmatrix} 1\\ 0\\  \vdots \\ 0
\end{pmatrix}.\]}

\lang{de}{
Genauso ist die zweite Spalte eine Lösung des LGS
\[ A\cdot \begin{pmatrix} x_1\\ x_2\\ \vdots \\ x_n
\end{pmatrix} = \begin{pmatrix} 0\\ 1\\  \vdots \\ 0
\end{pmatrix},\]}
\lang{en}{
In the same way, the second column is a solution of the linear system
\[ A\cdot \begin{pmatrix} x_1\\ x_2\\ \vdots \\ x_n
\end{pmatrix} = \begin{pmatrix} 0\\ 1\\  \vdots \\ 0
\end{pmatrix},\]}

\lang{de}{
etc., und die letzte  Spalte eine Lösung des LGS
\[ A\cdot \begin{pmatrix} x_1\\ x_2\\ \vdots \\ x_n
\end{pmatrix} = \begin{pmatrix} 0\\  \vdots \\ 0\\ 1
\end{pmatrix}.\]}
\lang{en}{
We go on the same way and then the last column is a solution of the linear system
\[ A\cdot \begin{pmatrix} x_1\\ x_2\\ \vdots \\ x_n
\end{pmatrix} = \begin{pmatrix} 0\\  \vdots \\ 0\\ 1
\end{pmatrix}.\]}

\lang{de}{
Um die inverse Matrix $B$ zu bestimmen, müssen also $n$ LGS der Form $Ax=v$ gelöst werden zu
den rechten Seiten 
\[ v=e_1= \begin{pmatrix} 1\\ 0\\  \vdots \\ 0
\end{pmatrix}, \ldots, v=e_n=\begin{pmatrix} 0\\  \vdots \\ 0\\ 1
\end{pmatrix}.\]}
\lang{en}{
To determine the inverse matrix $B$, we need to solve $n$ linear system $Ax=v$ for the right sides
\[ v=e_1= \begin{pmatrix} 1\\ 0\\  \vdots \\ 0
\end{pmatrix}, \ldots, v=e_n=\begin{pmatrix} 0\\  \vdots \\ 0\\ 1
\end{pmatrix}.\]}

\lang{de}{
Gibt es umgekehrt für jedes $j=1,\ldots,n$ eine Lösung $b_j$  des LGS $A x=e_j$, dann gilt für die Matrix $B$,
die die Spalten $b_1,\ldots,b_n$ hat, $A\cdot B=E_n$.

Um zu entscheiden, ob ein LGS $(A|v)$ eine Lösung besitzt und um diese direkt ablesen zu können, 
bringt man es in
\ref[content_41_gauss_verfahren1][reduzierte Stufenform]{def:stufenformen}.}
\lang{en}{
Conversely, if there is for every $j=1,\ldots,n$ a solution $b_j$ of the linear system $A x=e_j$, then for the matrix $B$ with
columns $b_1,\ldots,B_n$ holds, that $A\cdot B=I_n$.

To decide, if a linear system $(A|b)$ is solvable and to read the solution, we transform is into 
\ref[content_41_gauss_verfahren1][reduced row echelon form]{def:stufenformen}.}

\lang{de}{
Die elementaren Zeilenumformungen, die man dafür benötigt, bestimmen sich aber allein aus der Matrix $A$ und nicht aus der rechten Seite $v$.
Wir können sie also simultan für alle rechten Seiten $e_j$ gleichzeitig ausführen. 
Damit bringen wir also das LGS $(A|E_n)$ auf seine reduzierte Stufenform $(D|B)$ mit einer oberen Dreiecksmatrix $D$,
auf deren Diagonalen nur Einsen oder Nullen stehen. Dabei ist die Anzahl der Einsen gleich dem \ref[content_45_matrixrang][Rang]{sec:zeilenrang-spaltenrang}  von $A$.}
\lang{en}{
The necessary row transformations, are determined by the matrix $A$, not(!) the right side $v$.
Therefore we can perform them simulatiously for all right sides $e_j$.
This way we transform the linear system $(A|I_n)$ into its reduced row echelon form $(D|B)$ with an upper triangular matrix $D$,
with only $0$ and $1$ on its diagonal. The number of ones is equal to the \ref[content_45_matrixrang][rank]{sec:zeilenrang-spaltenrang}  of $A$.}

\begin{example}\label{ex:stufenform-beispiel}
\begin{tabs*}
\tab{\lang{de}{Invertierbare Matrix} \lang{en}{Invertible matrix}} 
\lang{de}{
Für die Matrix $A = \begin{pmatrix}
1 & 2 \\ 0& 2 \end{pmatrix} \in M(2;\R) $ erhält man 
\[  {(A\,|\, E_2)}=  \begin{pmatrix}
1 & 2 &| & 1 & 0 \\ 0& 2 &| & 0 & 1\end{pmatrix}\,\begin{matrix}  / - \text{(II)}\\  \phantom{1} \end{matrix} \rightsquigarrow  \begin{pmatrix}
1 & 0 &| & 1 & -1 \\ 0& 2 &| & 0 & 1\end{pmatrix}\,\begin{matrix}\phantom{1}\\ /\cdot\frac{1}{2}\end{matrix}\rightsquigarrow
\begin{pmatrix} 1&0&|&1&-1\\0&1&|&0&\frac{1}{2}\end{pmatrix}. \]
Die Matrix $A$ hat also vollen Rang $2$.
Hierbei sind die Spalten der rechten Seite die Lösungen von $Ax=e_1$ bzw. $Ax=e_2$. Also ist $A^{-1}=\begin{pmatrix}
1 & -1 \\ 0& \frac{1}{2}
\end{pmatrix}$ die inverse Matrix zu $A$.}
\lang{en}{
For the matrix $A = \begin{pmatrix}
1 & 2 \\ 0& 2 \end{pmatrix} \in M(2;\R) $ we get
\[  {(A\,|\, I_2)}=  \begin{pmatrix}
1 & 2 &| & 1 & 0 \\ 0& 2 &| & 0 & 1\end{pmatrix}\,\begin{matrix}  / - \text{(II)}\\  \phantom{1} \end{matrix} \rightsquigarrow  \begin{pmatrix}
1 & 0 &| & 1 & -1 \\ 0& 2 &| & 0 & 1\end{pmatrix}\,\begin{matrix}\phantom{1}\\ /\cdot\frac{1}{2}\end{matrix}\rightsquigarrow
\begin{pmatrix} 1&0&|&1&-1\\0&1&|&0&\frac{1}{2}\end{pmatrix}. \]
The matrix $A$ has full rank $2$.
Here the columns of the right side are the solutions of $Ax=e_1$ and $Ax=e_2$. So,  $A^{-1}=\begin{pmatrix}
1 & -1 \\ 0& \frac{1}{2}
\end{pmatrix}$ is the inverse matrix of $A$.}

\tab{\lang{de}{Nicht invertierbare Matrix} \lang{en}{Non-invertible matrix}}
\lang{en}{
For the matrix $B = \begin{pmatrix}
1 & 1 \\ 2& 2 \end{pmatrix} \in M(2;\R) $ we get
\[  {(B\,|\, I_2)}=  \begin{pmatrix}
1 & 1 &| & 1 & 0 \\ 2& 2 &| & 0 & 1\end{pmatrix}\,
\begin{matrix} \phantom{1}\\ / - 2\cdot\text{(I)}   \end{matrix}
\rightsquigarrow  
\begin{pmatrix}
1 & 1 &| & 1 & 0 \\ 0& 0 &| & -2 & 1\end{pmatrix}.\]
We have a zero-row in the reduced row echelon form. So the matrix $B$ does not have full rank, but the right side of the second row
is unequal to $0$.
Therefore the linear system $(B|I_2)$ has no solution and $B$ is not invertible.}
\lang{de}{
Für die Matrix $B = \begin{pmatrix}
1 & 1 \\ 2& 2 \end{pmatrix} \in M(2;\R) $ bekommen wir
\[  {(B\,|\, I_2)}=  \begin{pmatrix}
1 & 1 &| & 1 & 0 \\ 2& 2 &| & 0 & 1\end{pmatrix}\,
\begin{matrix} \phantom{1}\\ / - 2\cdot\text{(I)}   \end{matrix}
\rightsquigarrow  
\begin{pmatrix}
1 & 1 &| & 1 & 0 \\ 0& 0 &| & -2 & 1\end{pmatrix}.\]
In der reduzierten Zeilenstufenform haben wir eine Nullzeile. Damit hat die Matrix $B$ keinen voll Rang, aber die rechte Seite
der zweiten Zeile ist ungleich $0$.
Das LGS $(B|E_2)$ hat keine Lösung und $B$ ist nicht invertierbar.}
\end{tabs*}

\lang{de}{
Das folgende Video zeigt, wie die inverse Matrix mit Hilfe des Gauß-Algorithmus bestimmt werden kann: 
\floatright{\href{https://api.stream24.net/vod/getVideo.php?id=10962-2-10877&mode=iframe&speed=true}{\image[75]{00_video_button_schwarz-blau}}}}

\end{example}


\begin{theorem}[\lang{de}{Inverse Matrix} \lang{en}{The inverse matrix}]\label{rule:invertierbarkeit-rang}\label{thm:invertierbarkeit-rang}
\lang{de}{Eine quadratische Matrix $A\in M(n;\K)$ ist genau dann invertierbar, wenn die reduzierte Stufenform der Matrix $(A\,|\, E_n)$ die Gestalt $(E_n\,|\, B)$ hat.
In dem Fall ist $B$ die zu $A$ inverse Matrix.
\\
Erhält man eine andere reduzierte Stufenform,  so ist $A$ nicht invertierbar.

Eine Matrix $A\in M(n;\K)$ ist also genau dann invertierbar, wenn sie vollen Rang hat.}

\lang{en}{A square matrix $A\in M(n;\K)$ is invertible if and only if the reduced row echelon form of $(A\,|\, I_n)$ has the same shape as $(I_n\,|\, B)$.
Here $B$ is the inverse matrix of $A$.
\\
If the reduced row echelon form looks different, then $A$ is not invertible.

So a matrix $A\in M(n;\K)$ is invertible if and only if its rank is full.}
% Um festzustellen, ob eine quadratische Matrix $A\in M(n;\K)$ invertierbar ist, und um gegebenfalls ihre inverse Matrix $A^{-1}$ zu bestimmen, bringt man die Matrix $(A\,|\, E_n)$ auf reduzierte Stufenform. 

% Erhält man eine Matrix der Form $(E_n\,|\, B)$, hat also $A$ den Rang $n$, so ist $A$ invertierbar und
% $B$ ist die eindeutige inverse Matrix zu $A$.

% Erhält man eine andere reduzierte Stufenform, hat also $A$ einen Rang kleiner $n$, so ist $A$ nicht invertierbar.
\end{theorem}

\begin{remark}
% Der Rang einer Matrix gibt also Auskunft darüber, ob die Matrix invertierbar ist oder nicht:\\
% Hat die Matrix vollen Rang, ist sie invertierbar, hat sie keinen vollen Rang, ist sie nicht invertierbar.
%
\lang{de}{Im \link{determinante}{nächsten Abschnitt} werden wir ein weiteres Kriterium kennenlernen, um zu entscheiden, ob eine Matrix invertierbar ist, nämlich die sogenannte \emph{Determinante} der Matrix.}
\lang{en}{In the \link{determinante}{next section} we will get to know another criteria to decide, if a matrix is invertible. The criteria is called \emph{the determinant} of a matrix.}
\end{remark}


\begin{proof*}[\lang{de}{Beweis des Satzes} \lang{en}{Proof of the theorem}]
\begin{showhide}
\lang{en}{Because of our preliminary thoughts we already now, that a square matrix $A$ is invertible, if the reduced row rechelon form
of $(A\,|\,I_n)$ has the same shape as $(I_n\,|\,B)$. Then $B=A^{-1}$ is an inverse matrix of $A$.
Especially the rank of $A$ is equal to the rank of $I_n$, which is $n$, because the rank does not change during row transformations.}
\lang{de}{
Durch unsere Vorüberlegungen wissen wir schon, dass eine quadratische Matrix $A$ invertierbar ist, 
wenn die zu $(A\,|\,E_n)$ reduzierte Stufenform von der Gestalt $(E_n\,|\,B)$ ist, und dass dann $B=A^{-1}$ eine inverse Matrix zu $A$ ist. 
Insbesondere ist dann der Rang von $A$ gleich dem von $E_n$, also gleich $n$, denn der Rang bleibt durch elementare Zeilenumformungen unverändert.}

\lang{de}{
Ist andererseits die reduzierte Stufenform $(D\,|\,B)$ von $(A\,|\,E_n)$ nicht von dieser Gestalt, dann tritt in $D$ mindestens eine Nullzeile auf. Das heisst, $A$ hat nicht vollen Rang.
Denn der Rang bleibt durch die elementaren Zeilenumformungen unverändert. Deshalb hat aber auch $B$ denselben Rang wie $E_n$, also $n$.
Dann kann aber $B$ keine Nullzeile haben. Somit erhalten wir im LGS $(D\,|\,B)$ eine unerfüllbare Bedingung. 
Damit ist auch das LGS $(A\,|\,E_n)$ unlösbar. Es existiert keine inverse Matrix zu $A$.}
\lang{en}{
On the other hand, is the reduced row echelon form $(D\,|\,B)$ of $(A\,|\,I_n)$ not in this shape, then there is a least one zero-row in $D$.
That means, $A$ does not have full rank, because row transformations do not change the rank. Because of that $B$ has the same rank as $I_n$, so $n$.
Then $B$ can not have a zero-row. So we get an unsolvable condition in $(D\,|\,B)$.
Therefore the linear system $(A\,|\,I_n)$ is not solvable and there does not exist an inverse matrix of $A$.}
%
%
% Durch die Vorüberlegung haben wir schon gesehen, dass die Spalten der inversen Matrix die
% Lösungen der linearen Gleichungssysteme mit linker Seite $A$ und rechter Seite der Spalten von $E_n$ sind. Die Lösungen lassen sich - wie im \ref[gauss-verfahren][Abschnitt Gauß-Verfahren]{sec:mehrere-rechte-seiten} erklärt - simultan bestimmen, indem man die Matrix
% $(A\,|\, E_n)$ auf reduzierte Stufenform bringt und dann die entsprechenden LGS löst.

% Allgemein ist nun die reduzierte Stufenform zu $(A\,|\, E_n)$ eine Matrix $(S\,|\, D)$, wobei
% $S$ tatsächlich in Stufenform ist. Die Anzahl der von $0$ verschiedenen Zeilen von $S$ ist also gleich dem Rang von $A$.
% Da $D$ aus $E_n$ durch Zeilenumformungen entstanden ist, sind die Ränge beider Matrizen gleich, das heißt, $D$ hat Rang $n$. Insbesondere besitzt $D$ keine Nullzeile.

% Ist nun der Rang von $A$ kleiner als $n$, so ist die letzte Zeile von $S$ gleich $0$, die letzte Zeile von $D$ jedoch nicht, weshalb eines der zu $(S\,|\, D)$ gehörenden Gleichungssysteme
% nicht lösbar ist. In diesem Fall lassen sich also nicht alle zu $(A\,|\, E_n)$ gehörenden Gleichungssysteme lösen, weshalb es keine Matrix $B$ mit $A\cdot B=E_n$ gibt. D.h. $A$ ist nicht invertierbar.

% Hat $A$ jedoch vollen Rang $n$, so ist  $S=E_n$ und die reduzierte Stufenform zu $(A\,|\, E_n)$ von der Form $(E_n\,|\, D)$,
% also entsprechend dem Gleichungssystem mit linker Seite $E_n$. Dadurch erhält man als eindeutige Lösungen der entsprechenden 
% Gleichungssysteme direkt die Spalten von $D$.\\
% $A$ ist in diesem Fall also invertierbar und $B=D$ ist die eindeutige inverse Matrix zu $A$.
\end{showhide}
\end{proof*}
\begin{quickcheck}
     \text{\lang{de}{Markieren Sie alle invertierbaren Matrizen.} \lang{en}{Select alle the invertible matrices.}}
  \begin{choices}{multiple}
      \begin{choice}
        \text{$A=\begin{pmatrix}0&0\\1&0\end{pmatrix}$}
        \solution{false}
      \end{choice}
      \begin{choice}
        \text{$B=\begin{pmatrix}0&3&0\\4&8&0\\3&1&0\end{pmatrix}$}
        \solution{false}
      \end{choice}
%       \begin{choice}
%         \text{$C=\begin{pmatrix}0&0&0&8\\0&0&3&0\\0&4&0&0\\1&0&0&0\end{pmatrix}$}
%         \solution{true}
%       \end{choice}
      \begin{choice}
        \text{$C=\begin{pmatrix}0&0&0&8i\\0&0&3-i&0\\0&4&0&0\\1+i&0&0&0\end{pmatrix}$}
        \solution{true}
      \end{choice}
      \begin{choice}
        \text{$D=\begin{pmatrix}1&2&-2\\-2&-4&4\\0&3&1\end{pmatrix}$}
        \solution{false}
      \end{choice}
      \end{choices}
      \explanation{
      \lang{de}{Die Matrix $A$ hat eine Nullzeile, also nicht vollen Rang. Die Matrix $B$ hat eine Nullspalte, also nicht vollen Rang. 
      Matrix $D$ hat ebenfalls nicht vollen Rang: Addiert man das zweifache der ersten zur zweiten Zeile, entsteht eine Nullzeile. Also sind die Matrizen $A$, $B$, $D$ nicht invertierbar.
      Matrix $C$ hat hingegen vollen Rang und ist damit invertierbar. 
      Man kann sie sogar durch Zeilenvertauschung auf Diagonalgestalt bringen, worin alle Diagonaleinträge von null verschieden sind.}
      \lang{en}{The matrix $A$ has a zero-row, so not a full rank. The matrix $B$ has a zero-column, so not a full rank too.
      The rank of matrix $D$ is not full, because the result of adding twice the first row to the second is a zero-row. 
      Matrix $C$ has full rank and is therefore invertible. It can be transformed into a diagonal form by swapping rows. Then it is easy to see,
      that all the diagonal entries a unequal to $0$.}}
    
\end{quickcheck}


\lang{de}{
Aus denselben Ideen lassen sich weitere interessante und nützliche Folgerungen ziehen.}
\lang{en}{The same ideas can be used to draw the following conclusions.}
\begin{remark}
\begin{enumerate}
\item[(i)]
\lang{de}{
Eine quadratische Matrix $A\in M(n;\K)$ hat genau dann Rang $n$, wenn das LGS $Ax=v$ für \emph{jedes} $v\in\K^n$ eine Lösung besitzt.}
\lang{en}{
A square matrix $A\in M(n;\K)$ has rank $n$ if and only if, the linear system $Ax=v$ has a solution for \emph{every} $v\in\K^n$.}
\item[(ii)]
\lang{de}{
Ist $B\in M(n;\K)$ die inverse Matrix von $A\in M(n,\K)$, dann gilt nicht nur $A\cdot B=E_n$, sondern auch
\[B\cdot A=E_n.\]}
\lang{en}{
If $B\in M(n;\K)$ is the inverse matrix of $A\in M(n,\K)$, then it holds not only $A\cdot B=I_n$, but also \[B\cdot A=I_n.\]}
\item[(iii)]
\lang{de}{
Die Inverse einer quadratischen Matrix $A\in M(n;\K)$ ist eindeutig bestimmt. 
Das heißt, gilt $A\cdot B=E_n=A\cdot C$ für zwei Matrizen $B,C\in M(n;\K)$, dann ist $B=C$.}
\lang{en}{
The inverse of a square matrix $A\in M(n;\K)$ is uniquely determined. That is, if $A\cdot B=I_n=A\cdot C$ holds for two matrices
$B,C\in M(n;\K)$, then is $B=C$.}
\end{enumerate}
\end{remark}
\begin{proof*}
\begin{showhide}
\begin{enumerate}
\item[(i)]
\lang{de}{
Die Invertierbarkeit von $A$ ist gleich bedeutend dazu, dass $A$ Rang $n$ hat. Also können wir jetzt einfach die Lösung von $Ax=v$ 
angeben, wenn der Rang von $A$ gleich $n$ ist.
Diese ist nämlich $A^{-1}v$. Denn es ist $A\cdot(A^{-1}v)=(A\cdot A^{-1})v=E_nv=v$, nach dem \ref[content_43_matrizenmultiplikation][Assoziativgesetz der Matrixmultiplikation]{rule:rechenregeln}. 

Hat umgekehrt die Gleichung $Ax=v$ für jedes $v\in\K^n$ eine Lösung, dann gibt es insbesondere Lösungen $b_1,\ldots,b_n\in\K^n$ von $Ab_1=e_1, \ldots, Ab_n=e_n$. 
Fassen wir diese Spalten $b_j$ zusammen zu einer Matrix $B\in M(n,\K)$, so erhalten wir gerade die Inverse zu $A$.}

\lang{en}{
The invertibility of $A$ is equal to $A$ having the rank $n$. So we can give the solution of $Ax=v$, if the rank of $A$ is equal to $n$.
The solutions is $A^{-1}v$. Because we have $A\cdot(A^{-1}v)=(A\cdot A^{-1})v=I_nv=v$, using the \ref[content_43_matrizenmultiplikation][associative property of matrix multiplication]{rule:rechenregeln}. 

Conversely, if the equation $Ax=v$ has a solution for every $v\in\K^n$, then there are especially solutions $b_1,\ldots,b_n\in\K^n$ of $Ab_1=e_1, \ldots, Ab_n=e_n$.
If we merge the columns $b_j$ in a matrix $B\in M(n,\K)$, we receive exactly the inverse of $A$.}

\item[(ii)]
\lang{de}{
Die elementaren Zeilenumformungen von $(A\,|\, E_n)$ zu $(E_n\,|\, B)$ lassen sich  durch Multiplikation mit
einer $(n\times n)$-Matrix von links beschreiben, die gerade das Produkt der entsprechenden Elementarmatrizen ist. Bezeichnen wir diese Matrix mit $C\in M(n;\K)$, so gilt
\[   C\cdot (A\,|\, E_n) = (E_n\,|\, B),\]
was gleichbedeutend ist zu
\[ C\cdot A=E_n\qquad \text{und} \qquad C\cdot E_n=B. \]
Weil nun $C\cdot E_n=C$ ist, folgt aus der rechten Gleichung  $C=B$. Damit folgt aus der
linken Gleichung
\[ B\cdot A=E_n. \]}
\lang{en}{
The used row transformations, while transforming$(A\,|\, I_n)$ into $(I_n\,|\, B)$, can be collected in a $(n\times n)$-matrix. This matrix
is the product of the corresponding elementary matrices 
and is multiplied onto $(A\,|\, I_n)$ from the left.
We name this matrix $C$, with $C\in M(n;\K)$. Then we have
\[   C\cdot (A\,|\, I_n) = (I_n\,|\, B),\]
which is equal to
\[ C\cdot A=I_n\qquad \text{and} \qquad C\cdot I_n=B. \]
Because we have $C\cdot I_n=C$, we can conclude $C=B$ from the right equation.
Then the left equation gives us
\[ B\cdot A=I_n. \]}

\item[(iii)]
\lang{de}{
Gilt neben $A\cdot B=E_n$ auch noch $A\cdot C=E_n$ für  $A,B;C\in M(n;\K)$, dann gilt also $A\cdot B=A\cdot C$.
Durch Multiplikation von links mit $B$ folgt
$B\cdot (A\cdot B)=B\cdot (A\cdot C)$. Nach den Rechenregeln für Matrizen ist das gleichbedeutend zu $(B\cdot A)\cdot B=(B\cdot A)\cdot C$.
Nach (ii) ist aber $B\cdot A=E_n$, also erhalten wir $E_n\cdot B= E_n\cdot C$, was heißt $B=C$.}
\lang{en}{
If $A\cdot B=I_n$ and $A\cdot C=I_n$ hold for  $A,B,C\in M(n;\K)$, $A\cdot B=A\cdot C$ also holds.
By multiplying with $B$ from the left, we get
$B\cdot (A\cdot B)=B\cdot (A\cdot C)$. Because of the calculating rules of matrices this is equal to $(B\cdot A)\cdot B=(B\cdot A)\cdot C$.
But because of (ii) we have $B\cdot A=I_n$, which is why we get $I_n\cdot B= I_n\cdot C$. That means $B=C$.}
\end{enumerate}
\end{showhide}
\end{proof*}

\begin{example}\label{ex:inverse-berechnen}
\begin{tabs*}
\tab{\lang{de}{1. Beispiel} \lang{en}{1. Example}} 
\lang{de}{Für die Matrix $A = \begin{pmatrix}
1 & 2 \\ 0& 1 \end{pmatrix} \in M(2;\R) $ erhält man direkt
\[  {(A\,|\, E_2)}=  \begin{pmatrix}
1 & 2 &| & 1 & 0 \\ 0& 1 &| & 0 & 1\end{pmatrix}\,\begin{matrix}  / - 2\cdot \text{(II)}\\  \phantom{1} \end{matrix} \rightsquigarrow  \begin{pmatrix}
1 & 0 &| & 1 & -2 \\ 0& 1 &| & 0 & 1\end{pmatrix}. \]
Also ist $A^{-1}=\begin{pmatrix}
1 & -2 \\ 0& 1
\end{pmatrix}$.}
\lang{en}{For the matrix $A = \begin{pmatrix}
1 & 2 \\ 0& 1 \end{pmatrix} \in M(2;\R) $ we receive
\[  {(A\,|\, I_2)}=  \begin{pmatrix}
1 & 2 &| & 1 & 0 \\ 0& 1 &| & 0 & 1\end{pmatrix}\,\begin{matrix}  / - 2\cdot \text{(II)}\\  \phantom{1} \end{matrix} \rightsquigarrow  \begin{pmatrix}
1 & 0 &| & 1 & -2 \\ 0& 1 &| & 0 & 1\end{pmatrix}. \]
So the inverse is $A^{-1}=\begin{pmatrix}
1 & -2 \\ 0& 1
\end{pmatrix}$.}

\tab{\lang{de}{2. Beispiel} \lang{en}{2. Example}} 
\lang{de}{
Für die Matrix $B = \begin{pmatrix}
3 & 2 \\ -1& 1
\end{pmatrix} \in M(2;\R) $ berechnet man
\begin{eqnarray*}
{(B\,|\, I_2)} &=&  \begin{pmatrix}
3 & 2 &| & 1 & 0 \\ -1& 1 &| & 0 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  +\frac{1}{3}\cdot \text{(I)} \end{matrix} \\
& \rightsquigarrow &  \begin{pmatrix}
3 & 2 &| & 1 & 0 \\ 0& 5/3 &| & 1/3 & 1\end{pmatrix}\,\begin{matrix} /\cdot\frac{1}{3} \\  /  \cdot\frac{3}{5} \end{matrix} \\
& \rightsquigarrow &  \begin{pmatrix}
1 & 2/3 &| & 1/3 & 0 \\ 0& 1 &| & 1/5 & 3/5\end{pmatrix}\,\begin{matrix}  /  -\frac{2}{3}\cdot \text{(II)} \\ \phantom{1}  \end{matrix} \\
& \rightsquigarrow &  \begin{pmatrix}
1 & 0 &| & 3/15 & -2/5 \\ 0& 1 &| & 1/5 & 3/5\end{pmatrix}.
\end{eqnarray*}
Also ist $ B^{-1}=\begin{pmatrix}
1/5 & -2/5 \\ 1/5& 3/5
\end{pmatrix}$.}
\lang{en}{
For the matrix $B = \begin{pmatrix}
3 & 2 \\ -1& 1
\end{pmatrix} \in M(2;\R) $ we receive
\begin{eqnarray*}
{(B\,|\, E_2)} &=&  \begin{pmatrix}
3 & 2 &| & 1 & 0 \\ -1& 1 &| & 0 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  +\frac{1}{3}\cdot \text{(I)} \end{matrix} \\
& \rightsquigarrow &  \begin{pmatrix}
3 & 2 &| & 1 & 0 \\ 0& 5/3 &| & 1/3 & 1\end{pmatrix}\,\begin{matrix} /\cdot\frac{1}{3} \\  /  \cdot\frac{3}{5} \end{matrix} \\
& \rightsquigarrow &  \begin{pmatrix}
1 & 2/3 &| & 1/3 & 0 \\ 0& 1 &| & 1/5 & 3/5\end{pmatrix}\,\begin{matrix}  /  -\frac{2}{3}\cdot \text{(II)} \\ \phantom{1}  \end{matrix} \\
& \rightsquigarrow &  \begin{pmatrix}
1 & 0 &| & 3/15 & -2/5 \\ 0& 1 &| & 1/5 & 3/5\end{pmatrix}.
\end{eqnarray*}
So the inverse is $ B^{-1}=\begin{pmatrix}
1/5 & -2/5 \\ 1/5& 3/5
\end{pmatrix}$.}
% \tab{3. Beispiel}
% Für die Matrix $C = \begin{pmatrix}
% 1 & 4 \\ -1& 1
% \end{pmatrix} \in M(2;\R) $ berechnet man
% \begin{eqnarray*}
% {(C\,|\, E_2)} &=&  \begin{pmatrix}
% 1 & 4 &| & 1 & 0 \\ -1& 1 &| & 0 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  +\text{(I)} \end{matrix} \\
% &\rightsquigarrow&  \begin{pmatrix}
% 1 & 4 &| & 1 & 0 \\ 0 & 5 &| & 1 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  \cdot \frac{1}{5} \end{matrix} \\
% &\rightsquigarrow&  \begin{pmatrix}
% 1 & 4 &| & 1 & 0 \\ 0 & 1 &| & 1/5 & 1/5\end{pmatrix}\,\begin{matrix}/ -4\cdot \text{(II)}\\ \phantom{1} \end{matrix} \\
% &\rightsquigarrow&  \begin{pmatrix}
% 1 & 0 &| & 1/5 & -4/5 \\ 0 & 1 &| & 1/5 & 1/5\end{pmatrix}.
% \end{eqnarray*}
% Also ist $ C^{-1}=\begin{pmatrix}
% 1/5 & -4/5 \\ 1/5& 1/5
% \end{pmatrix}$.

\tab{\lang{de}{3. Beispiel} \lang{en}{3. Example}}
\lang{de}{
Für die Matrix $C = \begin{pmatrix}
i & 4 \\ -i& 1
\end{pmatrix} \in M(2;\C) $ berechnet man
\begin{eqnarray*}
{(C\,|\, I_2)} &=&  \begin{pmatrix}
i& 4 &| & 1 & 0 \\ -i& 1 &| & 0 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  +\text{(I)} \end{matrix} \\
&\rightsquigarrow&  \begin{pmatrix}
i & 4 &| & 1 & 0 \\ 0 & 5 &| & 1 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  \cdot \frac{1}{5} \end{matrix} \\
&\rightsquigarrow&  \begin{pmatrix}
i & 4 &| & 1 & 0 \\ 0 & 1 &| & \frac{1}{5} & \frac{1}{5}\end{pmatrix}\,\begin{matrix}/ -4\cdot \text{(II)}\\ \phantom{1} \end{matrix} \\
&\rightsquigarrow&  \begin{pmatrix}
i & 0 &| & \frac{1}{5} & -\frac{4}{5} \\ 0 & 1 &| & \frac{1}{5} & \frac{1}{5}\end{pmatrix}\,\begin{matrix}/ \cdot \frac{1}{i}\\ \phantom{1} \end{matrix} \\
&\rightsquigarrow& \begin{pmatrix}
1 & 0 &| & -\frac{i}{5} & \frac{4i}{5} \\ 0 & 1 &| & \frac{1}{5} & \frac{1}{5}\end{pmatrix}
\end{eqnarray*}
Also ist $ C^{-1}=\begin{pmatrix}
-i/5 & 4i/5 \\ 1/5& 1/5
\end{pmatrix}=\frac{1}{5}\begin{pmatrix}
-i & 4i \\ 1& 1\end{pmatrix}$.}
\lang{en}{
For the matrix $C = \begin{pmatrix}
i & 4 \\ -i& 1
\end{pmatrix} \in M(2;\C) $ we calculate
\begin{eqnarray*}
{(C\,|\, E_2)} &=&  \begin{pmatrix}
i& 4 &| & 1 & 0 \\ -i& 1 &| & 0 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  +\text{(I)} \end{matrix} \\
&\rightsquigarrow&  \begin{pmatrix}
i & 4 &| & 1 & 0 \\ 0 & 5 &| & 1 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  \cdot \frac{1}{5} \end{matrix} \\
&\rightsquigarrow&  \begin{pmatrix}
i & 4 &| & 1 & 0 \\ 0 & 1 &| & 1/5 & 1/5\end{pmatrix}\,\begin{matrix}/ -4\cdot \text{(II)}\\ \phantom{1} \end{matrix} \\
&\rightsquigarrow&  \begin{pmatrix}
i & 0 &| & 1/5 & -4/5 \\ 0 & 1 &| & 1/5 & 1/5\end{pmatrix}\,\begin{matrix}/ \cdot \frac{1}{i}\\ \phantom{1} \end{matrix} \\
&\rightsquigarrow& \begin{pmatrix}
1 & 0 &| & -i/5 & 4i/5 \\ 0 & 1 &| & 1/5 & 1/5\end{pmatrix}
\end{eqnarray*}
So the inverse is $ C^{-1}=\begin{pmatrix}
-i/5 & 4i/5 \\ 1/5& 1/5
\end{pmatrix}=\frac{1}{5}\begin{pmatrix}
-i & 4i \\ 1& 1\end{pmatrix}$.}
%%
% \tab{4. Beispiel}
% Für die Matrix $D = \begin{pmatrix}
% 1 & -2 \\ -1& 2
% \end{pmatrix} \in M(2;\R) $ berechnet man
% \begin{eqnarray*}
% {(D\,|\, E_2)} &=&  \begin{pmatrix}
% 1 & -2 &| & 1 & 0 \\ -1& 2 &| & 0 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  +\text{(I)} \end{matrix} \\
% &\rightsquigarrow&  \begin{pmatrix}
% 1 & -2 &| & 1 & 0 \\ 0 & 0 &| & 1 & 1\end{pmatrix}.
% \end{eqnarray*}
% Die linke Seite ist in reduzierter Stufenform gegeben, aber nicht die Einheitsmatrix.
% Der Rang der Matrix $D$ ist lediglich $1$. Deshalb ist $D$ nicht invertierbar.
%%
\tab{\lang{de}{4. Beispiel} \lang{en}{4. Example}}
\lang{de}{Für die Matrix $D = \begin{pmatrix}
1 & -2 \\ -i& 2i
\end{pmatrix} \in M(2;\C) $ berechnet man
\begin{eqnarray*}
{(D\,|\, E_2)} &=&  \begin{pmatrix}
1 & -2 &| & 1 & 0 \\ -i& 2i &| & 0 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  +i\cdot\text{(I)} \end{matrix} \\
&\rightsquigarrow&  \begin{pmatrix}
1 & -2 &| & 1 & 0 \\ 0 & 0 &| & i & 1\end{pmatrix}.
\end{eqnarray*}
Die linke Seite ist in reduzierter Stufenform gegeben, aber nicht die Einheitsmatrix.
Der Rang der Matrix $D$ ist lediglich $1$. Deshalb ist $D$ nicht invertierbar.}
\lang{en}{For the matrix $D = \begin{pmatrix}
1 & -2 \\ -i& 2i
\end{pmatrix} \in M(2;\C) $ we calcute
\begin{eqnarray*}
{(D\,|\, I_2)} &=&  \begin{pmatrix}
1 & -2 &| & 1 & 0 \\ -i& 2i &| & 0 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  +i\cdot\text{(I)} \end{matrix} \\
&\rightsquigarrow&  \begin{pmatrix}
1 & -2 &| & 1 & 0 \\ 0 & 0 &| & i & 1\end{pmatrix}.
\end{eqnarray*}
The left side is in reduced row echelon form, but it is not the identity matrix.
The rank of $D$ is only $1$, which is why $D$ is not invertible.}
\end{tabs*}
\end{example}

\lang{de}{
Aus dem allgemeinen Verfahren lässt sich für $(2\times 2)$-Matrizen die folgende Formel für die
inverse Matrix herleiten.}
\lang{en}{
We can derive the following formula for the inverse matrix of a $(2\times 2)$-matrix from the general method.}

\begin{rule}\label{rule:inverse-2x2}
\lang{de}{
Eine $(2\times 2)$-Matrix $A= \begin{pmatrix}
a & b \\ c& d \end{pmatrix} \in M(2;\K) $ ist genau dann invertierbar, wenn
$ad-bc\neq 0$ gilt. In diesem Fall ist die inverse Matrix gegeben durch
\[ A^{-1}= \frac{1}{ad-bc}\begin{pmatrix}
d & -b \\ -c& a \end{pmatrix}. \]}
\lang{en}{
A $(2\times 2)$-matrix $A= \begin{pmatrix}
a & b \\ c& d \end{pmatrix} \in M(2;\K) $ is invertible if and only if
$ad-bc\neq 0$ holds. In this case the inverse matrix is
\[ A^{-1}= \frac{1}{ad-bc}\begin{pmatrix}
d & -b \\ -c& a \end{pmatrix}. \]}
\end{rule}

\lang{en}{
\begin{example}
\begin{tabs*}
\tab{1. Example} 
Consider the matrix $A = \begin{pmatrix}
1 & 2 \\ 1& 3 \end{pmatrix} \in M(2;\R) $.\\
Here we have $a\cdot d - b\cdot c= 1\cdot 3- 2\cdot 1=1\neq 0$.\\
So the matrix $A$ is invertible. The inverse matrix is
$A^{-1}=\frac{1}{1}\begin{pmatrix}
3 & -2 \\ -1 & 1 \end{pmatrix}=
\begin{pmatrix}
3 & -2 \\ -1& 1
\end{pmatrix}$.
\tab{2. Example}
Consider the matrix $B = \begin{pmatrix}
6 & -3 \\ -2& 1 \end{pmatrix} \in M(2;\R) $.\\
Here we have $a\cdot d - b\cdot c= 6\cdot 1- (-2)\cdot (-3)=6-6=0$.\\
Therefore the matrix $B$ is not invertible.
\end{tabs*}
\end{example}}

\lang{de}{
Im folgenden Video findet man einige Beispielaufgaben zur Regel:
\floatright{\href{https://api.stream24.net/vod/getVideo.php?id=10962-2-11379&mode=iframe&speed=true}{\image[75]{00_video_button_schwarz-blau}}}}\\


~\\

\begin{proof*}[\lang{de}{Beweis der Regel} \lang{en}{Proof of the rule}]
\begin{showhide}
\lang{de}{
Wir führen das obige Verfahren im Fall $a\neq 0$ durch:
\[
{(A\,|\, E_2)} =  \begin{pmatrix}
a & b &| & 1 & 0 \\ c& d &| & 0 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  -\frac{c}{a}\cdot \text{(I)} \end{matrix} 
 \rightsquigarrow   \begin{pmatrix}
a & b &| & 1 & 0 \\ 0& (ad-bc)/a &| & -c/a & 1\end{pmatrix} \]}
\lang{en}{
We perform the above method for $a\neq 0$:
\[
{(A\,|\, I_2)} =  \begin{pmatrix}
a & b &| & 1 & 0 \\ c& d &| & 0 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  -\frac{c}{a}\cdot \text{(I)} \end{matrix} 
 \rightsquigarrow   \begin{pmatrix}
a & b &| & 1 & 0 \\ 0& (ad-bc)/a &| & -c/a & 1\end{pmatrix} \]}

\lang{de}{
Der Rang von $A$ ist also genau dann $2$, wenn $ad-bc\neq 0$ ist. In diesem Fall rechnen wir weiter:
\begin{eqnarray*}
&& \begin{pmatrix}
a & b &| & 1 & 0 \\ 0& (ad-bc)/a &| & -c/a & 1\end{pmatrix}\,\begin{matrix}  /  \cdot \frac{1}{a}
\\  /\cdot \frac{a}{ad-bc} \end{matrix}\\
& \rightsquigarrow &  \begin{pmatrix}
1 & b/a &| & 1/a & 0 \\ 0& 1 &| & -c/(ad-bc) & a/(ad-bc)\end{pmatrix}\,\begin{matrix}  /  -\frac{b}{a}\cdot \text{(II)} \\ \phantom{1}  \end{matrix} \\
& \rightsquigarrow &  \begin{pmatrix}
1 & 0 &| & \frac{1}{a}+\frac{bc}{a(ad-bc)} & -\frac{b}{ad-bc} \\ 0& 1 &| & -\frac{c}{ad-bc} & \frac{a}{ad-bc}\end{pmatrix}
\end{eqnarray*}}
\lang{en}{
The rank of $A$ is equal to $2$ exactly if $ad-bc\neq 0$. In this case we continue:
\begin{eqnarray*}
&& \begin{pmatrix}
a & b &| & 1 & 0 \\ 0& (ad-bc)/a &| & -c/a & 1\end{pmatrix}\,\begin{matrix}  /  \cdot \frac{1}{a}
\\  /\cdot \frac{a}{ad-bc} \end{matrix}\\
& \rightsquigarrow &  \begin{pmatrix}
1 & b/a &| & 1/a & 0 \\ 0& 1 &| & -c/(ad-bc) & a/(ad-bc)\end{pmatrix}\,\begin{matrix}  /  -\frac{b}{a}\cdot \text{(II)} \\ \phantom{1}  \end{matrix} \\
& \rightsquigarrow &  \begin{pmatrix}
1 & 0 &| & \frac{1}{a}+\frac{bc}{a(ad-bc)} & -\frac{b}{ad-bc} \\ 0& 1 &| & -\frac{c}{ad-bc} & \frac{a}{ad-bc}\end{pmatrix}
\end{eqnarray*}}

\lang{de}{
Also ist die inverse Matrix
\begin{eqnarray*} A^{-1} &=&  
\begin{pmatrix} \frac{1}{a}+\frac{bc}{a(ad-bc)} & -\frac{b}{ad-bc} \\  -\frac{c}{ad-bc} & \frac{a}{ad-bc}\end{pmatrix}\\
&=& \begin{pmatrix} \frac{ad}{a(ad-bc)} & -\frac{b}{ad-bc} \\  -\frac{c}{ad-bc} & \frac{a}{ad-bc}\end{pmatrix}\\
&=& \frac{1}{ad-bc}\cdot \begin{pmatrix}d & -b \\ -c& a \end{pmatrix}.
\end{eqnarray*}}
\lang{en}{
So the inverse matrix is
\begin{eqnarray*} A^{-1} &=&  
\begin{pmatrix} \frac{1}{a}+\frac{bc}{a(ad-bc)} & -\frac{b}{ad-bc} \\  -\frac{c}{ad-bc} & \frac{a}{ad-bc}\end{pmatrix}\\
&=& \begin{pmatrix} \frac{ad}{a(ad-bc)} & -\frac{b}{ad-bc} \\  -\frac{c}{ad-bc} & \frac{a}{ad-bc}\end{pmatrix}\\
&=& \frac{1}{ad-bc}\cdot \begin{pmatrix}d & -b \\ -c& a \end{pmatrix}.
\end{eqnarray*}}

\lang{de}{
Im Fall $a=0$ und $c\neq 0$ führt man das Verfahren entsprechend durch, wobei man im ersten Schritt die Zeilen vertauschen muss.

Falls $a$ und $c$ beide gleich $0$ sind, ist zum einen der Rang von $A$ kleiner als $2$ und zum anderen $ad-bc=0$. Auch in diesem Fall stimmt also die Behauptung.}

\lang{en}{
In case $a=0$ and $c\neq0$ we can perform the method analogously but with swapped rows in the first step.

If $a$ and $c$ are equal to zero, then the rank of $A$ is less then $2$ and on the other hand $ad-bc=0$. So in this case the claim is correct as well.}

\lang{de}{\floatright{\href{https://api.stream24.net/vod/getVideo.php?id=10962-2-11378&mode=iframe&speed=true}{\image[75]{00_video_button_schwarz-blau}}}}\\
\end{showhide}


%\floatright{\href{https://api.stream24.net/vod/getVideo.php?id=10962-2-10878&mode=iframe&speed=true}{\image[75]{00_video_button_schwarz-blau}}}\\


\end{proof*}
%\begin{quickcheckcontainer}
\begin{quickcheck}
  \type{input.number}
  \field{rational}
  \displayprecision{3}
  \correctorprecision{4}
 
  \begin{variables}
   \drawFromSet{d1}{2,3,4,5,6,7,8,9,-2,-3,-4,-5,-6,-7,-8,-9}
   \function[calculate]{a1}{d1}
   \function[calculate]{a2}{1}
   \function[calculate]{a3}{-1}
   \function[calculate]{a4}{0}
   
 \end{variables}
 
  \text{
  \lang{de}{
    Bestimmen Sie die inverse Matrix $B=\begin{pmatrix}b_{11}&b_{12}\\b_{21}&b_{22}\end{pmatrix}$ von $A=\begin{pmatrix}0&-1\\1&\var{d1}\end{pmatrix}$.
 
    Antwort: $b_{11}=$\ansref, $b_{12}=$\ansref, $b_{21}=$\ansref, $b_{22}=$\ansref.}
  \lang{en}{
    Determine the inverse matrix $B=\begin{pmatrix}b_{11}&b_{12}\\b_{21}&b_{22}\end{pmatrix}$ of $A=\begin{pmatrix}0&-1\\1&\var{d1}\end{pmatrix}$.
 
    Answer: $b_{11}=$\ansref, $b_{12}=$\ansref, $b_{21}=$\ansref, $b_{22}=$\ansref.}
  }
  
 
  \begin{answer}
    \solution{a1}
  \end{answer}
   \begin{answer}
    \solution{a2}
   \end{answer}
   \begin{answer}
    \solution{a3} 
  \end{answer}
  \begin{answer}
    \solution{a4}
   \end{answer}
\end{quickcheck}
%\end{quickcheckcontainer}

\lang{de}{
Auch für spezielle $(n\times n)$-Matrizen lassen sich leichte Regeln für die Invertierbarkeit herleiten.}
\lang{en}{
We can also derive easy rules for the invertibility of special $(n\times n)$-matrices. }


\begin{rule}
\begin{enumerate}
 \item[(i)] \lang{de}{Eine Diagonalmatrix $A=\text{diag}(a_{11},a_{22}, \cdots, a_{nn}) \in M(n;\K) $ ist genau dann invertierbar,
       wenn alle Eintr\"age $a_{ii} \neq 0$ sind f\"ur $1 \leq i \leq n$. In diesem Fall ist die Inverse gegeben durch 
       \[
       A^{-1}=\text{diag}\left(\frac{1}{a_{11}},\frac{1}{a_{22}}, \cdots, \frac{1}{a_{nn}}\right) \in M(n;\K).
       \]}
       \lang{en}{A diagonal matrix $A=\text{diag}(a_{11},a_{22}, \cdots, a_{nn}) \in M(n;\K) $ is invertible exactly if for 
       all entries holds $a_{ii} \neq 0$ for $1 \leq i \leq n$. Then the inverse matrix is 
       \[
       A^{-1}=\text{diag}\left(\frac{1}{a_{11}},\frac{1}{a_{22}}, \cdots, \frac{1}{a_{nn}}\right) \in M(n;\K).
       \]}
 \item[(ii)] \lang{de}{Eine obere bzw. untere Dreiecksmatrix ist genau dann invertierbar, wenn alle Diagonaleintr\"age ungleich $0$ sind. In diesem 
       Fall ist die Inverse wieder eine obere bzw. untere Dreiecksmatrix.}
       \lang{en}{A lower or upper triangular matrix is invertible exactly if all diagonal entries are unequal to $0$.
       Then the inverse is again a lower or upper triangular matrix.}
\end{enumerate}
\end{rule}
\begin{proof*}[\lang{de}{Beweis der Regel} \lang{en}{Proof of the rule}]
\begin{showhide}
\begin{enumerate}
\item[(i)] \lang{de}{Diese Regel hatten wir schon in diesem \ref[quadr-matrizen][Beispiel]{ex:erste-bsp_inverse_matrix} hergeleitet.
Es geht aber ebenso mit der reduzierten Stufenform: Um eine Diagonalmatrix auf reduzierte Stufenform zu bringen, muss man nur noch die $i$-te Zeile mit $d_i^{-1}$ multiplizieren, falls $d_i\neq 0$.
Falls alle $d_i\neq 0$, so erhält man also die inverse Matrix wie behauptet. Ist ein $d_i=0$, dann hat die Matrix eine Nullzeile, also keinen vollen Rang mehr. Dann ist sie also nicht invertierbar.}
\lang{en}{We already derived this rule in this \ref[quadr-matrizen][example]{ex:erste-bsp_inverse_matrix}.
But we can also derive the rule with the reduced row echelon form: To transform a diagonal matrix into reduced row echelon form, we only need to multiply the $i$th row with $d_i^{-1}$, if $d_i\neq 0$.
If all $d_i\neq 0$, we reveice the inverse matrix as stated. If one $d_i=0$, the matrix has a zero row and therefore not full rank.
The matrix is then not invertible.}

\item[(ii)]
\lang{de}{Eine obere Dreiecksmatrix $D$ ist bereits auf Stufengestalt. Sie hat genau dann vollen Rang, wenn alle Diagonaleinträge von null verschieden sind. Also ist sie auch genau dann invertierbar.
Ist das der Fall, dann muss man für die reduzierte Stufenform von $(D\,|\,E_n)$ die Diagonaleinträge von $D$ auf eins normieren und die Einträge oberhalb der Diagonale ausräumen.
Diese elementaren Zeilenumformungen führen insbesondere obere Dreiecksmatrizen in solche über, machen also auch aus der Einheitsmatrix eine obere Dreiecksmatrix. Somit ist die inverse Matrix von $D$ wieder eine obere Dreiecksmatrix.
\\
Für eine untere Dreiecksmatrix verfährt man analog.}
\lang{en}{A upper triangular matrix $D$ is already in row echelon form. Its rank is full if and only if all diagonal entries are unequal to $0$. Then the matrix is also invertible.
To receive the reduced row echelon form of $(D\,|\,I_n)$ we need to do two things: eliminate the entries above the main diagonal and norm the main diagonal entries to $1$.
Those elementary row transformations transform especially upper triangular matrices in such matrices, which is why they transform the identity matrix into an upper triangular matrix. 
Therefore the inverse of $D$ is again an upper triangular matrix.
\\
We can proceed in the same way for lower triangular matrices.}
\end{enumerate}
\end{showhide}
\end{proof*}


\section{\lang{de}{Rechenregeln für inverse Matrizen} \lang{en}{Calculating rules for inverse matrices}}\label{sec:rechenregeln}

\lang{de}{
Wir notieren noch weitere Rechenregeln für inverse Matrizen.}
\lang{en}{
We are going to note further calculating rules for inverse matrices.}

\begin{rule}
\lang{de}{
Sind $A,A_1,A_2\in M(n;\K)$  invertierbare Matrizen, dann gilt:}
\lang{en}{
Let $A,A_1,A_2\in M(n;\K)$ be invertible matrices, then we have:}
\begin{enumerate}
\item[(i)] \lang{de}{$A^{-1}\in M(n;\K)$ ist invertierbar und $(A^{-1})^{-1} = A$.} 
\lang{en}{$A^{-1}\in M(n;\K)$ is invertible and $(A^{-1})^{-1} = A$.}
\item[(ii)] \lang{de}{$A_1 \cdot A_2$ ist invertierbar und  
$(A_1 \cdot A_2)^{-1} = A_2^{-1} \cdot A_1^{-1}$.}
\lang{en}{$A_1 \cdot A_2$ is invertible and  
$(A_1 \cdot A_2)^{-1} = A_2^{-1} \cdot A_1^{-1}$.}
\end{enumerate}
\lang{de}{\floatright{\href{https://www.hm-kompakt.de/video?watch=831}{\image[75]{00_Videobutton_schwarz}}}}\\\\
\end{rule}

\begin{block}[warning]
\lang{de}{
Beim Produkt der inversen Matrizen ist also die Reihenfolge vertauscht!\\
$(A_1 \cdot A_2)^{-1} $ ist also \textbf{nicht} $A_1^{-1}\cdot A_2^{-1}$, sondern
\[ (A_1 \cdot A_2)^{-1} = A_2^{-1} \cdot A_1^{-1}.\]}
\lang{en}{
In the product of the inverse matrices the order is swapped!\\
$(A_1 \cdot A_2)^{-1} $ is \textbf{not} equal to $A_1^{-1}\cdot A_2^{-1}$, but
\[ (A_1 \cdot A_2)^{-1} = A_2^{-1} \cdot A_1^{-1}.\]}
\end{block}

\begin{proof*}[\lang{de}{Beweis der Regel} \lang{en}{Proof of the rule}]
\begin{showhide}
\begin{enumerate}
\item[(i)]
\lang{de}{
Wir hatten gesehen, dass für eine invertierbare Matrix $A$ nicht nur nach Definition der inversen Matrix 
$A\cdot A^{-1}=E_n$ ist, sondern auch $A^{-1}\cdot A=E_n$. Letztere
Gleichung sagt aber genau aus, dass $A^{-1}$ invertierbar ist und dass $A$ die inverse Matrix
zu $A^{-1}$ ist, also $(A^{-1})^{-1} = A$.}
\lang{en}{
We know, that for a invertible matrix $A$ and its inverse $A^{-1}$ holds $A\cdot A^{-1}=I_n$ and $A^{-1}\cdot A=I_n$.
The latter equation expresses, that $A^{-1}$ is invertible and that $A$ is the inverse matrix of $A^{-1}$, so $(A^{-1})^{-1} = A$.}
\item[(ii)]
\lang{de}{
Um nachzuweisen, dass $A_1 \cdot A_2$ invertierbar ist mit inverser Matrix $A_2^{-1} \cdot A_1^{-1}$, ist 
lediglich nachzurechnen, dass
\[ (A_1 \cdot A_2)\cdot (A_2^{-1} \cdot A_1^{-1})=E_n \]
gilt. Mit Hilfe des Assoziativgesetzes erhält man:
\begin{eqnarray*} 
(A_1 \cdot A_2)\cdot (A_2^{-1} \cdot A_1^{-1}) &=& 
\left((A_1 \cdot A_2)\cdot A_2^{-1}\right) \cdot A_1^{-1} \quad \text{Assoziativgesetz}\\
&=& \left( A_1 \cdot (A_2\cdot A_2^{-1})\right) \cdot A_1^{-1} \quad \text{Assoziativgesetz} \\
&=&  \left( A_1 \cdot E_n\right) \cdot A_1^{-1} \quad \text{Definition der Inversen }A_2^{-1} \\
&=&  A_1  \cdot A_1^{-1} \quad \text{Eigenschaft von }E_n \\
&=& E_n \quad \text{Definition der inversen }A_1^{-1} 
\end{eqnarray*}}
\lang{en}{
To verify, that $A_1 \cdot A_2$ is invertibly with the inverse matrix $A_2^{-1} \cdot A_1^{-1}$, we need to check, that 
\[ (A_1 \cdot A_2)\cdot (A_2^{-1} \cdot A_1^{-1})=I_n \]
gilt. Via the associative property we get:
\begin{eqnarray*} 
(A_1 \cdot A_2)\cdot (A_2^{-1} \cdot A_1^{-1}) &=& 
\left((A_1 \cdot A_2)\cdot A_2^{-1}\right) \cdot A_1^{-1} \quad \text{Associative property}\\
&=& \left( A_1 \cdot (A_2\cdot A_2^{-1})\right) \cdot A_1^{-1} \quad \text{Associative property} \\
&=&  \left( A_1 \cdot I_n\right) \cdot A_1^{-1} \quad \text{Definition of the inverse }A_2^{-1} \\
&=&  A_1  \cdot A_1^{-1} \quad \text{Property of }I_n \\
&=& I_n \quad \text{Definition of the inverse }A_1^{-1} 
\end{eqnarray*}}
\end{enumerate}
\end{showhide}
\end{proof*}



\begin{example}
\begin{incremental}[\initialsteps{1}]
\step
\lang{de}{
Im \lref{ex:inverse-berechnen}{obigen Beispiel} hatten wir die  inversen Matrizen zu
\[ A = \begin{pmatrix}
1 & 2 \\ 0& 1 \end{pmatrix} \in M(2;\R) \quad \text{und} \quad  B= \begin{pmatrix}
3 & 2 \\ -1& 1
\end{pmatrix} \in M(2;\R) \] 
berechnet, nämlich
\[ A^{-1}=\begin{pmatrix}
1 & -2 \\ 0& 1
\end{pmatrix} \quad \text{und} \quad  B^{-1}=\begin{pmatrix}
1/5 & -2/5 \\ 1/5& 3/5
\end{pmatrix}. \]}
\lang{en}{
In the \lref{ex:inverse-berechnen}{above example} we calculated the inverse matrix of
\[ A = \begin{pmatrix}
1 & 2 \\ 0& 1 \end{pmatrix} \in M(2;\R) \quad \text{und} \quad  B= \begin{pmatrix}
3 & 2 \\ -1& 1
\end{pmatrix} \in M(2;\R) \] 
which is
\[ A^{-1}=\begin{pmatrix}
1 & -2 \\ 0& 1
\end{pmatrix} \quad \text{und} \quad  B^{-1}=\begin{pmatrix}
\frac{1}{5} & -\frac{2}{5} \\ \frac{1}{5}& \frac{3}{5}
\end{pmatrix}. \]}

\step
\lang{de}{
Weiter ist 
\[ A\cdot B=\begin{pmatrix}
1 & 2 \\ 0& 1 \end{pmatrix}\cdot \begin{pmatrix}
3 & 2 \\ -1& 1
\end{pmatrix}=\begin{pmatrix}
1 & 4 \\ -1& 1
\end{pmatrix} \]
Die inverse Matrix zu $A\cdot B$ ist 
$(A\cdot B)^{-1}=\begin{pmatrix}
1/5 & -4/5 \\ 1/5& 1/5
\end{pmatrix}$ (vgl. drittes \lref{ex:inverse-berechnen}{Beispiel oben}).}
\lang{en}{
Further we have 
\[ A\cdot B=\begin{pmatrix}
1 & 2 \\ 0& 1 \end{pmatrix}\cdot \begin{pmatrix}
3 & 2 \\ -1& 1
\end{pmatrix}=\begin{pmatrix}
1 & 4 \\ -1& 1
\end{pmatrix} \]
The inverse matrix of $A\cdot B$ is 
$(A\cdot B)^{-1}=\begin{pmatrix}
\frac{1}{5} & -\frac{4}{5} \\ \frac{1}{5}& \frac{1}{5}
\end{pmatrix}$ (see the third \lref{ex:inverse-berechnen}{example above}).}

\step
\lang{de}{
Wir können nun direkt verifizieren, dass $(A\cdot B)^{-1}=B^{-1}\cdot A^{-1}$ ist, indem wir
das Produkt berechnen:
\[ B^{-1}\cdot A^{-1}= \begin{pmatrix}
1/5 & -2/5 \\ 1/5& 3/5
\end{pmatrix}\cdot \begin{pmatrix}
1 & -2 \\ 0& 1
\end{pmatrix} = \begin{pmatrix}
1/5 & -4/5 \\ 1/5& 1/5
\end{pmatrix}=(A\cdot B)^{-1}.\]}
\lang{en}{
Now we can verify, that $(A\cdot B)^{-1}=B^{-1}\cdot A^{-1}$ by determining the product:
\[ B^{-1}\cdot A^{-1}= \begin{pmatrix}
\frac{1}{5} & -\frac{2}{5} \\ \frac{1}{5}& \frac{3}{5}
\end{pmatrix}\cdot \begin{pmatrix}
1 & -2 \\ 0& 1
\end{pmatrix} = \begin{pmatrix}
\frac{1}{5} & -\frac{4}{5} \\ \frac{1}{5}& \frac{1}{5}
\end{pmatrix}=(A\cdot B)^{-1}.\]}

\step
\lang{de}{
Das Produkt $A^{-1}\cdot B^{-1}$ ist hingegen
\[ A^{-1}\cdot B^{-1} =  \begin{pmatrix}
1 & -2 \\ 0& 1
\end{pmatrix} \cdot  \begin{pmatrix}
1/5 & -2/5 \\ 1/5& 3/5
\end{pmatrix} = \begin{pmatrix}
-1/5 & -8/5 \\ 1/5& 3/5
\end{pmatrix} \neq (A\cdot B)^{-1}.\]}
\lang{en}{
However the product $A^{-1}\cdot B^{-1}$ is
\[ A^{-1}\cdot B^{-1} =  \begin{pmatrix}
1 & -2 \\ 0& 1
\end{pmatrix} \cdot  \begin{pmatrix}
\frac{1}{5} & -\frac{2}{5} \\ \frac{1}{5}& \frac{3}{5}
\end{pmatrix} = \begin{pmatrix}
-\frac{1}{5} & -\frac{8}{5}\\ \frac{1}{5}& \frac{3}{5}
\end{pmatrix} \neq (A\cdot B)^{-1}.\]}
\end{incremental}
\end{example}


% \begin{example}
% Im \lref{ex:inverse-berechnen}{obigen Beispiel} hatten wir die inverse Matrix zu
% $ B= \begin{pmatrix}
% 3 & 2 \\ -1& 1
% \end{pmatrix} \in M(2;\R) $ berechnet, nämlich
% $ B^{-1}=\begin{pmatrix}
% 1/5 & -2/5 \\ 1/5& 3/5
% \end{pmatrix}$.
% Dazu hatten wir die Matrix $(B\,|\,E_2)$ mittels Zeilenumformungen zu $(E_2\,|\,B^{-1})$ umgeformt. Um die Inverse zu 
% $B^{-1}$ zu bestimmen, starten wir also mit 
% $(B^{-1}\,|\,E_2)$ und wenden darauf Zeilenumformungen an.

% Wenn man nun genau die oben gemachten Zeilenumformungen rückgängig macht, endet man 
% aber automatisch bei der Matrix $(E_2\,|\,B)$, da ja lediglich die linken und rechten Seiten vertauscht sind. Also ist $B$ die inverse Matrix zu $B^{-1}$.\\
% Würde man auf $(B^{-1}\,|\,E_2)$ strikt das Gauß-Verfahren anwenden, würde man natürlich andere Zeilenumformungen machen, die daraus resultierende reduzierte Zeilenstufenform wäre aber dieselbe, wie folgende Rechnung zeigt.

% \begin{eqnarray*}
% (B^{-1}\,|\, E_2) &=&  \begin{pmatrix}
% 1/5 & -2/5 &| & 1& 0 \\  1/5 & 3/5 &| & 0 & 1\end{pmatrix}\,\begin{matrix} \phantom{1}\\  /  - \text{(I)} \end{matrix} \\
% & \rightsquigarrow &  \begin{pmatrix}
% 1/5 & -2/5 &| & 1 & 0 \\ 0& 1 &| & -1 & 1\end{pmatrix}\,\begin{matrix}\cdot 5 \\   \phantom{1} \end{matrix} \\
% & \rightsquigarrow &  \begin{pmatrix}
% 1 & -2 &| & 5 & 0 \\ 0& 1 &| & -1 & 1\end{pmatrix}\,\begin{matrix}  /  +2\cdot \text{(II)} \\ \phantom{1}  \end{matrix} \\
% & \rightsquigarrow &  \begin{pmatrix}
% 1 & 0 &| & 3 & 2 \\ 0& 1 &| & -1 & 1\end{pmatrix}.
% \end{eqnarray*}

% \end{example}

\lang{de}{
Zuletzt beschäftigen wir uns noch mit Inversen  \link{transponierte}{transponierter Matrizen}.}
\lang{en}{Last we employ ourselves with inverse \link{transponierte}{transposed matrices}. }

\begin{rule}\label{rule:inverse-transpose}
\lang{de}{
Sei $A\in M(n;\K)$ und $A^T\in M(n;\K)$ die transponierte Matrix zu $A$.

Die Matrix $A^T$ ist genau dann invertierbar, wenn $A$ invertierbar ist. Ist das der Fall,
dann gilt
\[   (A^T)^{-1}=(A^{-1})^T. \] 
D.h. die inverse Matrix zu $A^T$ ist genau die transponierte Matrix zu $A^{-1}$.}

\lang{en}{
Let $A^T\in M(n;\K)$ be the transpose of $A\in M(n;\K)$.

The matrix $A^T$ is invertible exactly if, $A$ is invertible. In thise case, it holds
\[   (A^T)^{-1}=(A^{-1})^T. \] 
Namely, the inverse matrix of $A^T$ is exactly the transpose of $A^{-1}$.}
\end{rule}

\begin{proof*}[\lang{de}{Beweis} \lang{en}{Proof}]
\begin{showhide}
\lang{de}{
Da die Ränge von $A$ und $A^T$ gleich sind (siehe \ref[umformungen][Abschnitt Zeilenumformungen mit Matrizen und Rang]{sec:zeilenrang-spaltenrang}), hat $A^T$ genau
dann vollen Rang, wenn $A$ vollen Rang hat, d.h. $A^T$ ist genau dann invertierbar, wenn
$A$ invertierbar ist.}
\lang{en}{
$A$ and $A^T$ have the same rank (see \ref[umformungen][Part "Row transformations by matrix multiplication and rank"]{sec:zeilenrang-spaltenrang}.
Therefore $A^T$ has full rank exactly if $A$ has full rank. That implies, that $A^T$ is invertible exaclty if $A$ is invertible.}

\lang{de}{
Ist nun $A$ invertierbar und $A^{-1}$ ihre Inverse, dann gilt nicht nur $A\cdot A^{-1}=E_n$,
sondern auch $A^{-1}\cdot A=E_n$.
Mit den \ref[transponierte][Rechenregeln für transponierte Matrizen]{sec:rechenregeln} erhalten wir aus der letzten Gleichung
\[  A^T\cdot (A^{-1})^T=\left(A^{-1}\cdot A \right)^T=E_n^T=E_n. \]
Also ist $(A^{-1})^T$ die inverse Matrix zu $A^T$.}
\lang{en}{
If $A$ is invertible and $A^{-1}$ is its invers, we have not only $A\cdot A^{-1}=I_n$,
but also $A^{-1}\cdot A=I_n$.
With the \ref[transponierte][calculating rules for transposed matrices]{sec:rechenregeln} we receive
\[  A^T\cdot (A^{-1})^T=\left(A^{-1}\cdot A \right)^T=I_n^T=I_n. \]
Therefore $(A^{-1})^T$ is the inverse of $A^T$.}
\end{showhide}
\end{proof*}
%\begin{quickcheckcontainer}
\begin{quickcheck}
 
      \text{
      \lang{de}{Die Matrix $A=\begin{pmatrix}1&2&3\\0&-1&4\\0&0&1\end{pmatrix}$ hat die Inverse
      $\begin{pmatrix} 1&2&-11\\0&-1&4\\0&0&1\end{pmatrix}$. Welche der folgenden Matrizen ist die inverse Matrix von $A^T$?}
      \lang{en}{
      The matrix $A=\begin{pmatrix}1&2&3\\0&-1&4\\0&0&1\end{pmatrix}$ has the inverse
      $\begin{pmatrix} 1&2&-11\\0&-1&4\\0&0&1\end{pmatrix}$. Which of the following matric is the inverse of $A^T$?}}
      
      \begin{choices}{unique}
     
  
      \begin{choice}
        \text{$\begin{pmatrix}1&4&-11\\0&-1&2\\0&0&1\end{pmatrix}$}
        \solution{false}
      \end{choice}

      \begin{choice}
        \text{$\begin{pmatrix}1&0&0\\2&-1&0\\-11&4&1\end{pmatrix}$}
        \solution{true}
      \end{choice}
      \begin{choice}
        \text{$\begin{pmatrix}1&0&0\\2&-1&0\\3&4&1\end{pmatrix}$}
        \solution{false}
      \end{choice}
\end{choices}
    
\end{quickcheck}
%\end{quickcheckcontainer}


\end{visualizationwrapper}

\end{content}